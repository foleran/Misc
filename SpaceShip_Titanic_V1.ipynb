{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8c1c92c6-26b2-4a34-8f56-ca3568b88e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "import os\n",
    "import optuna\n",
    "import lightgbm as lgb\n",
    "pd.set_option('display.max_columns', 50)\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "import gc\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a137f9f0-4453-4360-8deb-17d7f620683a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def DataPreparation(dfs, missing_values = False):\n",
    "    \n",
    "    for df in dfs:\n",
    "        df[['CabinDeck','CabinNum','CabinSide']] = df['Cabin'].str.split('/',expand=True)\n",
    "        df['CabinNum'] = df['CabinNum'].astype('float64')\n",
    "        cabinnumdiv = 500\n",
    "        df['CabinNumGroup'] = (np.floor(df['CabinNum']/cabinnumdiv)*cabinnumdiv).astype('object')\n",
    "        df.drop(['Name','Cabin','CabinNum'],axis=1,inplace=True)\n",
    "        df['Adult'] = 1\n",
    "        df.loc[df['Age']<18.0,'Adult']=0\n",
    "        \n",
    "        columnslist = ['RoomService','FoodCourt','ShoppingMall','Spa','VRDeck']\n",
    "        df['TotalSpent'] = df[columnslist].sum(axis=1)\n",
    "        df['TotalSpent_IsZero_Cryo_IsFalse'] = 0\n",
    "        df.loc[(df['TotalSpent']==0.0)&(df['CryoSleep']==False),'TotalSpent_IsZero_Cryo_IsFalse'] = 1\n",
    "        for col in columnslist:\n",
    "            df['Ratio_'+str(col)+'_TotalSpent'] = df[col].divide(df['TotalSpent'],axis=0,fill_value=np.nan)\n",
    "    \n",
    "        # df['LargestSpend'] = df[columnslist].max(axis=1)\n",
    "        # df['LargestSpendingArea'] = df[columnslist].idxmax(axis=1)\n",
    "        # df.loc[df['TotalSpent']==0,'LargestSpendingArea'] = np.nan\n",
    "        \n",
    "    train_noms, test_noms = LabelEncoding(dfs[0], dfs[1], 'PassengerId', 'Transported', missing_values = missing_values)    \n",
    "    \n",
    "    # for df in [train_noms,test_noms]:\n",
    "    #     columnlist1 = [col for col in df.columns if col.startswith('CabinDeck')]\n",
    "    #     columnlist2 = [col for col in df.columns if col.startswith('CabinNumGroup')]\n",
    "    #     for a in columnlist1:\n",
    "    #         df[[a+'_'+b for b in columnlist2]] = df[columnlist2].multiply(df[a],axis=0)        \n",
    "        \n",
    "    columnlist = list()\n",
    "    for col in dfs[0].drop(['PassengerId','Transported'],axis=1).columns:\n",
    "        if (dfs[0][col].dtypes!='float64') & (dfs[0][col].dtypes!='int64'):\n",
    "            columnlist.append(col)\n",
    "    train_nums = dfs[0].drop(columnlist+['Transported'], axis=1)\n",
    "    test_nums = dfs[1].drop(columnlist, axis=1)\n",
    "    \n",
    "    dfs[0] = train_noms.merge(train_nums, on = 'PassengerId', how = 'left')\n",
    "    dfs[1] = test_noms.merge(test_nums, on = 'PassengerId', how = 'left')\n",
    "    return dfs[0],dfs[1] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6101b2b-38b7-4b37-b05f-137eaac10250",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def LabelEncoding(df1, df2, ids, labels, missing_values = False):\n",
    "    \n",
    "    df1_finished = df1[[ids, labels]].copy()\n",
    "    df2_finished = df2[[ids]].copy()\n",
    "    \n",
    "    if not(missing_values):\n",
    "        for col in df1.drop([ids,labels],axis=1):\n",
    "            if (df1[col].dtypes != 'float64') & (df1[col].dtypes != 'int64'):\n",
    "                df1_dummies = pd.get_dummies(df1[[ids,col]],columns=[col])\n",
    "                df2_dummies = pd.get_dummies(df2[[ids,col]],columns=[col])\n",
    "                # if df1[col].isna().sum() !=0:\n",
    "                #     df1_dummies[col+'_Nan'] = df1[col].isna().astype('int')\n",
    "                #     df2_dummies[col+'_Nan'] = df2[col].isna().astype('int')\n",
    "                df1_finished = df1_finished.merge(df1_dummies, on=ids, how= 'left')\n",
    "                df2_finished = df2_finished.merge(df2_dummies, on=ids, how= 'left')\n",
    "    elif missing_values:\n",
    "        for col in df1.drop([ids,labels],axis=1):\n",
    "            if (df1[col].dtypes != 'float64') & (df1[col].dtypes != 'int64'):\n",
    "                if len(df1[col].dropna().unique().tolist())==2:\n",
    "                    df1_dummies = pd.DataFrame({'PassengerId':df1[ids], col : np.full(df1.shape[0],np.nan,dtype='int')})\n",
    "                    df2_dummies = pd.DataFrame({'PassengerId':df2[ids], col : np.full(df2.shape[0],np.nan,dtype='int')})\n",
    "                    for ind,value in enumerate(df1[col].dropna().unique().tolist()):                      \n",
    "                        df1_dummies.loc[df1[col]==value,col] = ind\n",
    "                        df2_dummies.loc[df2[col]==value,col] = ind\n",
    "                    df1_finished = df1_finished.merge(df1_dummies, on=ids, how= 'left')\n",
    "                    df2_finished = df2_finished.merge(df2_dummies, on=ids, how= 'left')\n",
    "                elif len(df1[col].dropna().unique().tolist())>2:\n",
    "                    df1_dummies = pd.get_dummies(df1[[ids,col]],columns=[col])\n",
    "                    df2_dummies = pd.get_dummies(df2[[ids,col]],columns=[col])\n",
    "                    # if df1[col].isna().sum() !=0:\n",
    "                    #     df1_dummies[col+'_Nan'] = df1[col].isna().astype('int')\n",
    "                    #     df2_dummies[col+'_Nan'] = df2[col].isna().astype('int')\n",
    "                    df1_finished = df1_finished.merge(df1_dummies, on=ids, how= 'left')\n",
    "                    df2_finished = df2_finished.merge(df2_dummies, on=ids, how= 'left')                    \n",
    "    \n",
    "    df1_labels = df1_finished[labels]\n",
    "    df1_finished, df2_finished = df1_finished.align(df2_finished, join = 'inner', axis = 1)\n",
    "    df1_finished[labels] = df1_labels\n",
    "    \n",
    "    return df1_finished,df2_finished"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "38cf7406-5b3e-48ba-8a4e-ee8d69dc5b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def BaselineModels(df1, df2, ids, labels, n_folds = 5, seed = 42069):\n",
    "    \n",
    "    df1_ids = df1[ids].copy()\n",
    "    df2_ids = df2[ids].copy()\n",
    "    \n",
    "    df1_labels = df1[labels].copy()\n",
    "    \n",
    "    df1_features = df1.fillna(0).drop([ids,labels],axis=1).copy()\n",
    "    df2_features = df2.fillna(0).drop([ids], axis=1).copy()\n",
    "    \n",
    "    \n",
    "    feat_names = df1_features.columns.tolist()\n",
    "    \n",
    "    df1_features = np.array(df1_features)\n",
    "    df2_features = np.array(df2_features)\n",
    "    \n",
    "    out_of_fold = np.zeros(df1_features.shape[0])\n",
    "    \n",
    "    display(df1)\n",
    "    \n",
    "    logreg = LogisticRegression(max_iter = 20000, random_state = seed)\n",
    "    gnb = GaussianNB()\n",
    "    clftree = DecisionTreeClassifier(random_state = seed)\n",
    "    \n",
    "    modelsdict = {'Logistic Regression' : logreg, 'Naive Bayes' : gnb, 'Classification Tree' : clftree}\n",
    "    \n",
    "    scores_dict = dict()\n",
    "    out_of_fold_dict = dict()\n",
    "    for basemodel in modelsdict:\n",
    "        scores_dict[basemodel] = np.zeros((n_folds+1,2),'float64')\n",
    "        out_of_fold_dict[basemodel] = np.zeros(df1_features.shape[0],'float64')\n",
    "        \n",
    "    k_fold = KFold(n_splits = n_folds, shuffle = True, random_state = seed)\n",
    "    k = 0\n",
    "    for train_indices, valid_indices in k_fold.split(df1_features):\n",
    "        \n",
    "        \n",
    "        train_features, train_labels = df1_features[train_indices], df1_labels[train_indices]\n",
    "        valid_features, valid_labels = df1_features[valid_indices], df1_labels[valid_indices]\n",
    "        \n",
    "        for basemodel in modelsdict:\n",
    "            \n",
    "            modelsdict[basemodel].fit(train_features, train_labels) \n",
    "\n",
    "        \n",
    "            train_preds = modelsdict[basemodel].predict_proba(train_features)[:,1]\n",
    "            train_auc_fold = roc_auc_score(train_labels,train_preds)\n",
    "            valid_preds = modelsdict[basemodel].predict_proba(valid_features)[:,1]\n",
    "            valid_auc_fold = roc_auc_score(valid_labels,valid_preds)\n",
    "            \n",
    "            scores_dict[basemodel][k,0] = train_auc_fold \n",
    "            scores_dict[basemodel][k,1] = valid_auc_fold \n",
    "            out_of_fold_dict[basemodel][valid_indices] = valid_preds\n",
    "        \n",
    "        k += 1\n",
    "    baseline_auc = np.zeros(len(modelsdict))\n",
    "    l = 0\n",
    "    for basemodel in modelsdict:\n",
    "        print('*************************** '+str(basemodel)+' ***************************')\n",
    "        for i in range(0,n_folds):\n",
    "            print('Fold ' + str(i+1) + ' --- Train AUC: ' + str(\"%.6f\" % round(scores_dict[basemodel][i,0], 6)) + '   Valid AUC: ' +  str(\"%.6f\" % round(scores_dict[basemodel][i,1], 6)))\n",
    "        valid_auc_all = roc_auc_score(df1_labels,out_of_fold_dict[basemodel])\n",
    "        baseline_auc[l]= valid_auc_all\n",
    "        l += 1\n",
    "        print('Overall AUC: '+str(\"%.6f\" % round(valid_auc_all, 6)))\n",
    "    \n",
    "    bestmodel = list(modelsdict.keys())[list(np.where(baseline_auc==np.amax(baseline_auc)))[0][0]]\n",
    "    modelsdict[bestmodel].fit(df1_features,df1_labels)\n",
    "    test_preds = modelsdict[bestmodel].predict(df2_features)\n",
    "    submission = pd.DataFrame({'PassengerId' : df2_ids, 'Transported' : test_preds})\n",
    "        \n",
    "    return submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af349ee8-56bc-4ce2-a1bf-fee8831f25b8",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def OptimizationObjectiveLogistic(trial, df1_ids, df1_labels, df1_features, n_folds = 5, seed = 42069):\n",
    "    \n",
    "    paramdict = {\n",
    "        'max_iter': trial.suggest_categorical('max_iter',[5000]),\n",
    "        'solver': trial.suggest_categorical('solver',['liblinear']),\n",
    "        'tol': trial.suggest_categorical('tol',[1e-4]),\n",
    "        'penalty': trial.suggest_categorical('penalty',['l1','l2']),\n",
    "        'C': trial.suggest_float('C',0.1,1,step=0.005),\n",
    "        }\n",
    "    \n",
    "    valid_auc = OptimizationLogisticModel(df1_ids, df1_labels, df1_features, params = paramdict, n_folds = n_folds , seed = seed)\n",
    "    \n",
    "    return valid_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "348a90fb-93f7-40ee-aebc-113efe767adf",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def OptimizationLogisticModel(df1_ids, df1_labels, df1_features, params, n_folds = 5, seed = 42069):\n",
    "\n",
    "    model = LogisticRegression(random_state = seed, **params)\n",
    "    \n",
    "    out_of_fold = np.zeros(df1_features.shape[0]) \n",
    "    \n",
    "    k_fold = KFold(n_splits = n_folds, shuffle = True, random_state = seed)\n",
    "    for train_indices, valid_indices in k_fold.split(df1_features):\n",
    "        \n",
    "        train_features, train_labels = df1_features[train_indices], df1_labels[train_indices]\n",
    "        valid_features, valid_labels = df1_features[valid_indices], df1_labels[valid_indices]    \n",
    "    \n",
    "        model.fit(train_features, train_labels)\n",
    "        valid_preds = model.predict_proba(valid_features)[:,1]\n",
    "        out_of_fold[valid_indices] = valid_preds\n",
    "        \n",
    "    valid_auc = log_loss(df1_labels,out_of_fold)        \n",
    "    \n",
    "    return valid_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ffc6d01a-0872-49af-ac59-d55bc0a9215f",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def FinalLogisticModel(df1_ids, df1_labels, df1_features, df2_ids, df2_features, params, n_folds = 5, seed = 42069):\n",
    "    \n",
    "    model = LogisticRegression(random_state = seed, **params)\n",
    "    \n",
    "    out_of_fold = np.zeros(df1_features.shape[0]) \n",
    "    \n",
    "    k_fold = KFold(n_splits = n_folds, shuffle = True, random_state = seed)\n",
    "    k=0\n",
    "    print('*************************** Final Logistic Regression Model***************************')\n",
    "    for train_indices, valid_indices in k_fold.split(df1_features):\n",
    "        k+=1\n",
    "        train_features, train_labels = df1_features[train_indices], df1_labels[train_indices]\n",
    "        valid_features, valid_labels = df1_features[valid_indices], df1_labels[valid_indices]    \n",
    "    \n",
    "        model.fit(train_features, train_labels)\n",
    "        train_preds = model.predict_proba(train_features)[:,1]\n",
    "        train_auc_fold = roc_auc_score(train_labels,train_preds)\n",
    "        valid_preds = model.predict_proba(valid_features)[:,1]\n",
    "        valid_auc_fold = roc_auc_score(valid_labels,valid_preds)\n",
    "        out_of_fold[valid_indices] = valid_preds\n",
    "        \n",
    "        print('   Fold '+str(k)+' ---- Train AUC: '+ str(\"%.6f\" % round(train_auc_fold, 6)) + '   Valid AUC: ' +  str(\"%.6f\" % round(valid_auc_fold, 6)))\n",
    "        \n",
    "    valid_auc = roc_auc_score(df1_labels,out_of_fold)\n",
    "    print('   Overall AUC:   '+str(\"%.6f\" % round(valid_auc, 6)))\n",
    "    \n",
    "    model.fit(df1_features,df1_labels)\n",
    "    test_preds = model.predict(df2_features)\n",
    "    submission = pd.DataFrame({'PassengerId' : df2_ids, 'Transported' : test_preds})\n",
    "    \n",
    "    return submission    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0a2fe6e1-9146-46d5-a148-a5c4924e83f5",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def OptimizationModel(df1, df2, ids, labels, n_folds = 5, seed = 42069):\n",
    "\n",
    "    df1_ids = df1[ids].copy()\n",
    "    df2_ids = df2[ids].copy()\n",
    "    \n",
    "    df1_labels = df1[labels].copy()\n",
    "    \n",
    "    df1_features = df1.fillna(0).drop([ids,labels],axis=1).copy()\n",
    "    df2_features = df2.fillna(0).drop([ids], axis=1).copy()\n",
    "    \n",
    "    feat_names = df1_features.columns.tolist()\n",
    "    \n",
    "    df1_features = np.array(df1_features)\n",
    "    df2_features = np.array(df2_features)\n",
    "\n",
    "    # optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "    study = optuna.create_study(direction='minimize', study_name='Logistic Regression')\n",
    "    func = lambda trial: OptimizationObjectiveLogistic(trial, df1_ids, df1_labels, df1_features, n_folds = n_folds, seed = seed)\n",
    "    study.optimize(func,n_trials=200)\n",
    "    bestparamsdict = dict(study.best_params.items())\n",
    "    \n",
    "    submission = FinalLogisticModel(df1_ids, df1_labels, df1_features, df2_ids, df2_features, params= bestparamsdict, n_folds = n_folds, seed = seed)\n",
    "    \n",
    "    return submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "68830997-5e3f-4e2d-809d-30f0b1ac0bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def OptimizationObjectiveLGBM(trial, df1_ids, df1_labels, df1_features, n_folds = 5, seed = 42069):\n",
    "    \n",
    "    paramdict = {\n",
    "        'n_estimators': trial.suggest_categorical('n_estimators', [10000]),\n",
    "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.5),\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 50, 250, step = 5),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 10, step = 1),\n",
    "        'min_child_samples': trial.suggest_int('min_child_samples', 50, 1000, step=10),\n",
    "        'reg_alpha': trial.suggest_int('reg_alpha', 0, 10, step=0.1),\n",
    "        'reg_lambda': trial.suggest_int('reg_lambda', 0, 10, step=0.1),\n",
    "        'min_split_gain': trial.suggest_float('min_split_gain', 0, 15, step = 0.5),\n",
    "        'subsample': trial.suggest_float('subsample', 0.4, 0.9, step=0.1),\n",
    "        'subsample_freq': trial.suggest_categorical('subsample_freq', [1]),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.4, 0.95, step=0.1)\n",
    "    } \n",
    "    \n",
    "    valid_auc = OptimizationLGBM(df1_ids, df1_labels, df1_features, params = paramdict, n_folds = n_folds , seed = seed)\n",
    "    \n",
    "    return valid_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "984eea13-8824-456b-88d3-8537c2ca336b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def OptimizationLGBM(df1_ids, df1_labels, df1_features, params, n_folds = 5, seed = 42069):\n",
    "    \n",
    "\n",
    "    model = lgb.LGBMClassifier(objective = 'binary', random_state = seed, **params)   \n",
    "    \n",
    "    out_of_fold = np.zeros(df1_features.shape[0]) \n",
    "    \n",
    "    k_fold = KFold(n_splits = n_folds, shuffle = True, random_state = seed)\n",
    "    for train_indices, valid_indices in k_fold.split(df1_features):\n",
    "        \n",
    "        train_features, train_labels = df1_features[train_indices], df1_labels[train_indices]\n",
    "        valid_features, valid_labels = df1_features[valid_indices], df1_labels[valid_indices]    \n",
    "    \n",
    "        model.fit(train_features, train_labels, eval_metric = 'auc', eval_set = [(valid_features, valid_labels), (train_features, train_labels)], eval_names = ['valid', 'train'], early_stopping_rounds = 200, verbose = -1)   \n",
    "        \n",
    "        bestiteration = model.best_iteration_\n",
    "        valid_preds = model.predict_proba(valid_features, num_iteration = bestiteration)[:,1]\n",
    "        out_of_fold[valid_indices] = valid_preds\n",
    "        \n",
    "#         gc.enable()\n",
    "#         del lgbmodel, train_features, valid_features\n",
    "#         gc.collect()        \n",
    "        \n",
    "    valid_auc = roc_auc_score(df1_labels,out_of_fold)        \n",
    "    \n",
    "    return valid_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aa90192a-f93a-4a90-84e8-59f7af74d263",
   "metadata": {},
   "outputs": [],
   "source": [
    "def FinalLGBM(df1_ids, df1_labels, df1_features, df2_ids, df2_features, params, n_folds = 5, seed = 42069):\n",
    "    \n",
    "    \n",
    "    model = lgb.LGBMClassifier(objective = 'binary', random_state = seed, **params)\n",
    "    \n",
    "    out_of_fold = np.zeros(df1_features.shape[0])\n",
    "    test_preds = np.zeros(df2_features.shape[0])\n",
    "    \n",
    "    k_fold = KFold(n_splits = n_folds, shuffle = True, random_state = seed)\n",
    "    k=0\n",
    "    print('*************************** Final Logistic Regression Model***************************')\n",
    "    for train_indices, valid_indices in k_fold.split(df1_features):\n",
    "        k+=1\n",
    "        train_features, train_labels = df1_features[train_indices], df1_labels[train_indices]\n",
    "        valid_features, valid_labels = df1_features[valid_indices], df1_labels[valid_indices]    \n",
    "    \n",
    "        model.fit(train_features, train_labels, eval_metric = 'auc',\n",
    "                  eval_set = [(valid_features, valid_labels), (train_features, train_labels)],\n",
    "                  eval_names = ['valid', 'train'], early_stopping_rounds = 300, verbose = -1)   \n",
    "        \n",
    "        bestiteration = model.best_iteration_        \n",
    "        \n",
    "        out_of_fold[valid_indices] = model.predict_proba(valid_features, num_iteration = bestiteration)[:, 1]        \n",
    "        valid_auc_fold = model.best_score_['valid']['auc']\n",
    "        train_auc_fold = model.best_score_['train']['auc']\n",
    "        \n",
    "        print('   Fold '+str(k)+' ---- Train AUC: '+ str(\"%.6f\" % round(train_auc_fold, 6)) + '   Valid AUC: ' +  str(\"%.6f\" % round(valid_auc_fold, 6)))\n",
    "        \n",
    "        test_preds += model.predict_proba(df2_features, num_iteration = bestiteration)[:, 1] / k_fold.n_splits\n",
    "        \n",
    "    valid_auc = roc_auc_score(df1_labels,out_of_fold)\n",
    "    print('   Overall AUC:   '+str(\"%.6f\" % round(valid_auc, 6)))\n",
    "    \n",
    "    # model.fit(train_features, train_labels, eval_metric = 'auc',\n",
    "    #           eval_set = [(valid_features, valid_labels), (train_features, train_labels)],\n",
    "    #           eval_names = ['valid', 'train'], early_stopping_rounds = 200, verbose = -1)  \n",
    "    # test_preds = model.predict(df2_features)\n",
    "    submission = pd.DataFrame({'PassengerId' : df2_ids, 'Transported' : test_preds})\n",
    "    \n",
    "    return submission  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "227dd4b8-7b2d-4afc-9d10-36f6fc261ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def OptimizationModelLGBM(df1, df2, ids, labels, n_folds = 5, seed = 42069):\n",
    "\n",
    "    df1_ids = df1[ids].copy()\n",
    "    df2_ids = df2[ids].copy()\n",
    "    \n",
    "    df1_labels = df1[labels].copy()\n",
    "    \n",
    "    \n",
    "    # Change HOT encoding for binary nominals with nan values, LBM handles NaN value\n",
    "    df1_features = df1.drop([ids,labels],axis=1).copy()\n",
    "    df2_features = df2.drop([ids], axis=1).copy()\n",
    "    \n",
    "    feat_names = df1_features.columns.tolist()\n",
    "    \n",
    "    df1_features = np.array(df1_features)\n",
    "    df2_features = np.array(df2_features)\n",
    "\n",
    "    # optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "    study = optuna.create_study(direction='maximize', study_name='LGBM Classifier')\n",
    "    func = lambda trial: OptimizationObjectiveLGBM(trial, df1_ids, df1_labels, df1_features, n_folds = n_folds, seed = seed)\n",
    "    study.optimize(func,n_trials=200)\n",
    "    bestparamsdict = dict(study.best_params.items())\n",
    "    \n",
    "    submission = FinalLGBM(df1_ids, df1_labels, df1_features, df2_ids, df2_features, params= bestparamsdict, n_folds = n_folds, seed = seed)\n",
    "    \n",
    "    submission['Transported_class'] = False\n",
    "    submission.loc[submission['Transported']>=0.5,'Transported_class'] = True\n",
    "    submission['Transported'] = submission['Transported_class']\n",
    "    submission.drop('Transported_class',axis=1,inplace=True)\n",
    "    \n",
    "    return submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a73a4489-82ad-4e2a-97e2-b1921599f8fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>HomePlanet</th>\n",
       "      <th>CryoSleep</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Destination</th>\n",
       "      <th>Age</th>\n",
       "      <th>VIP</th>\n",
       "      <th>RoomService</th>\n",
       "      <th>FoodCourt</th>\n",
       "      <th>ShoppingMall</th>\n",
       "      <th>Spa</th>\n",
       "      <th>VRDeck</th>\n",
       "      <th>Name</th>\n",
       "      <th>Transported</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0001_01</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>B/0/P</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>39.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Maham Ofracculy</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0002_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>F/0/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>24.0</td>\n",
       "      <td>False</td>\n",
       "      <td>109.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>549.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>Juanna Vines</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0003_01</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>A/0/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>58.0</td>\n",
       "      <td>True</td>\n",
       "      <td>43.0</td>\n",
       "      <td>3576.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6715.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>Altark Susent</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0003_02</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>A/0/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>33.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1283.0</td>\n",
       "      <td>371.0</td>\n",
       "      <td>3329.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>Solam Susent</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0004_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>F/1/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>16.0</td>\n",
       "      <td>False</td>\n",
       "      <td>303.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Willy Santantines</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8688</th>\n",
       "      <td>9276_01</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>A/98/P</td>\n",
       "      <td>55 Cancri e</td>\n",
       "      <td>41.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6819.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1643.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>Gravior Noxnuther</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8689</th>\n",
       "      <td>9278_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>True</td>\n",
       "      <td>G/1499/S</td>\n",
       "      <td>PSO J318.5-22</td>\n",
       "      <td>18.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Kurta Mondalley</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8690</th>\n",
       "      <td>9279_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>G/1500/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>26.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1872.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Fayey Connon</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8691</th>\n",
       "      <td>9280_01</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>E/608/S</td>\n",
       "      <td>55 Cancri e</td>\n",
       "      <td>32.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1049.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>353.0</td>\n",
       "      <td>3235.0</td>\n",
       "      <td>Celeon Hontichre</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8692</th>\n",
       "      <td>9280_02</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>E/608/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>44.0</td>\n",
       "      <td>False</td>\n",
       "      <td>126.0</td>\n",
       "      <td>4688.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>Propsh Hontichre</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8693 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId HomePlanet CryoSleep     Cabin    Destination   Age    VIP  \\\n",
       "0        0001_01     Europa     False     B/0/P    TRAPPIST-1e  39.0  False   \n",
       "1        0002_01      Earth     False     F/0/S    TRAPPIST-1e  24.0  False   \n",
       "2        0003_01     Europa     False     A/0/S    TRAPPIST-1e  58.0   True   \n",
       "3        0003_02     Europa     False     A/0/S    TRAPPIST-1e  33.0  False   \n",
       "4        0004_01      Earth     False     F/1/S    TRAPPIST-1e  16.0  False   \n",
       "...          ...        ...       ...       ...            ...   ...    ...   \n",
       "8688     9276_01     Europa     False    A/98/P    55 Cancri e  41.0   True   \n",
       "8689     9278_01      Earth      True  G/1499/S  PSO J318.5-22  18.0  False   \n",
       "8690     9279_01      Earth     False  G/1500/S    TRAPPIST-1e  26.0  False   \n",
       "8691     9280_01     Europa     False   E/608/S    55 Cancri e  32.0  False   \n",
       "8692     9280_02     Europa     False   E/608/S    TRAPPIST-1e  44.0  False   \n",
       "\n",
       "      RoomService  FoodCourt  ShoppingMall     Spa  VRDeck               Name  \\\n",
       "0             0.0        0.0           0.0     0.0     0.0    Maham Ofracculy   \n",
       "1           109.0        9.0          25.0   549.0    44.0       Juanna Vines   \n",
       "2            43.0     3576.0           0.0  6715.0    49.0      Altark Susent   \n",
       "3             0.0     1283.0         371.0  3329.0   193.0       Solam Susent   \n",
       "4           303.0       70.0         151.0   565.0     2.0  Willy Santantines   \n",
       "...           ...        ...           ...     ...     ...                ...   \n",
       "8688          0.0     6819.0           0.0  1643.0    74.0  Gravior Noxnuther   \n",
       "8689          0.0        0.0           0.0     0.0     0.0    Kurta Mondalley   \n",
       "8690          0.0        0.0        1872.0     1.0     0.0       Fayey Connon   \n",
       "8691          0.0     1049.0           0.0   353.0  3235.0   Celeon Hontichre   \n",
       "8692        126.0     4688.0           0.0     0.0    12.0   Propsh Hontichre   \n",
       "\n",
       "      Transported  \n",
       "0           False  \n",
       "1            True  \n",
       "2           False  \n",
       "3           False  \n",
       "4            True  \n",
       "...           ...  \n",
       "8688        False  \n",
       "8689        False  \n",
       "8690         True  \n",
       "8691        False  \n",
       "8692         True  \n",
       "\n",
       "[8693 rows x 14 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv(os.getcwd()+'\\\\train.csv')\n",
    "test = pd.read_csv(os.getcwd()+'\\\\test.csv')\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0b5cd0d7-dbd9-426a-848b-ec45fccc7b8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>HomePlanet_Earth</th>\n",
       "      <th>HomePlanet_Europa</th>\n",
       "      <th>HomePlanet_Mars</th>\n",
       "      <th>CryoSleep</th>\n",
       "      <th>Destination_55 Cancri e</th>\n",
       "      <th>Destination_PSO J318.5-22</th>\n",
       "      <th>Destination_TRAPPIST-1e</th>\n",
       "      <th>VIP</th>\n",
       "      <th>CabinDeck_A</th>\n",
       "      <th>CabinDeck_B</th>\n",
       "      <th>CabinDeck_C</th>\n",
       "      <th>CabinDeck_D</th>\n",
       "      <th>CabinDeck_E</th>\n",
       "      <th>CabinDeck_F</th>\n",
       "      <th>CabinDeck_G</th>\n",
       "      <th>CabinDeck_T</th>\n",
       "      <th>CabinSide</th>\n",
       "      <th>CabinNumGroup_0.0</th>\n",
       "      <th>CabinNumGroup_500.0</th>\n",
       "      <th>CabinNumGroup_1000.0</th>\n",
       "      <th>CabinNumGroup_1500.0</th>\n",
       "      <th>Transported</th>\n",
       "      <th>Age</th>\n",
       "      <th>RoomService</th>\n",
       "      <th>FoodCourt</th>\n",
       "      <th>ShoppingMall</th>\n",
       "      <th>Spa</th>\n",
       "      <th>VRDeck</th>\n",
       "      <th>Adult</th>\n",
       "      <th>TotalSpent</th>\n",
       "      <th>TotalSpent_IsZero_Cryo_IsFalse</th>\n",
       "      <th>Ratio_RoomService_TotalSpent</th>\n",
       "      <th>Ratio_FoodCourt_TotalSpent</th>\n",
       "      <th>Ratio_ShoppingMall_TotalSpent</th>\n",
       "      <th>Ratio_Spa_TotalSpent</th>\n",
       "      <th>Ratio_VRDeck_TotalSpent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0001_01</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0002_01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>24.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>549.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>1</td>\n",
       "      <td>736.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.148098</td>\n",
       "      <td>0.012228</td>\n",
       "      <td>0.033967</td>\n",
       "      <td>0.745924</td>\n",
       "      <td>0.059783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0003_01</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>58.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>3576.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6715.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>1</td>\n",
       "      <td>10383.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.004141</td>\n",
       "      <td>0.344409</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.646730</td>\n",
       "      <td>0.004719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0003_02</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1283.0</td>\n",
       "      <td>371.0</td>\n",
       "      <td>3329.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5176.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.247875</td>\n",
       "      <td>0.071677</td>\n",
       "      <td>0.643161</td>\n",
       "      <td>0.037287</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0004_01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>16.0</td>\n",
       "      <td>303.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1091.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.277727</td>\n",
       "      <td>0.064161</td>\n",
       "      <td>0.138405</td>\n",
       "      <td>0.517874</td>\n",
       "      <td>0.001833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8688</th>\n",
       "      <td>9276_01</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>41.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6819.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1643.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>1</td>\n",
       "      <td>8536.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.798852</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.192479</td>\n",
       "      <td>0.008669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8689</th>\n",
       "      <td>9278_01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8690</th>\n",
       "      <td>9279_01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1872.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1873.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.999466</td>\n",
       "      <td>0.000534</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8691</th>\n",
       "      <td>9280_01</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1049.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>353.0</td>\n",
       "      <td>3235.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4637.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.226224</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.076127</td>\n",
       "      <td>0.697649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8692</th>\n",
       "      <td>9280_02</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>44.0</td>\n",
       "      <td>126.0</td>\n",
       "      <td>4688.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4826.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.026109</td>\n",
       "      <td>0.971405</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002487</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8693 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  HomePlanet_Earth  HomePlanet_Europa  HomePlanet_Mars  \\\n",
       "0        0001_01                 0                  1                0   \n",
       "1        0002_01                 1                  0                0   \n",
       "2        0003_01                 0                  1                0   \n",
       "3        0003_02                 0                  1                0   \n",
       "4        0004_01                 1                  0                0   \n",
       "...          ...               ...                ...              ...   \n",
       "8688     9276_01                 0                  1                0   \n",
       "8689     9278_01                 1                  0                0   \n",
       "8690     9279_01                 1                  0                0   \n",
       "8691     9280_01                 0                  1                0   \n",
       "8692     9280_02                 0                  1                0   \n",
       "\n",
       "      CryoSleep  Destination_55 Cancri e  Destination_PSO J318.5-22  \\\n",
       "0             0                        0                          0   \n",
       "1             0                        0                          0   \n",
       "2             0                        0                          0   \n",
       "3             0                        0                          0   \n",
       "4             0                        0                          0   \n",
       "...         ...                      ...                        ...   \n",
       "8688          0                        1                          0   \n",
       "8689          1                        0                          1   \n",
       "8690          0                        0                          0   \n",
       "8691          0                        1                          0   \n",
       "8692          0                        0                          0   \n",
       "\n",
       "      Destination_TRAPPIST-1e  VIP  CabinDeck_A  CabinDeck_B  CabinDeck_C  \\\n",
       "0                           1    0            0            1            0   \n",
       "1                           1    0            0            0            0   \n",
       "2                           1    1            1            0            0   \n",
       "3                           1    0            1            0            0   \n",
       "4                           1    0            0            0            0   \n",
       "...                       ...  ...          ...          ...          ...   \n",
       "8688                        0    1            1            0            0   \n",
       "8689                        0    0            0            0            0   \n",
       "8690                        1    0            0            0            0   \n",
       "8691                        0    0            0            0            0   \n",
       "8692                        1    0            0            0            0   \n",
       "\n",
       "      CabinDeck_D  CabinDeck_E  CabinDeck_F  CabinDeck_G  CabinDeck_T  \\\n",
       "0               0            0            0            0            0   \n",
       "1               0            0            1            0            0   \n",
       "2               0            0            0            0            0   \n",
       "3               0            0            0            0            0   \n",
       "4               0            0            1            0            0   \n",
       "...           ...          ...          ...          ...          ...   \n",
       "8688            0            0            0            0            0   \n",
       "8689            0            0            0            1            0   \n",
       "8690            0            0            0            1            0   \n",
       "8691            0            1            0            0            0   \n",
       "8692            0            1            0            0            0   \n",
       "\n",
       "      CabinSide  CabinNumGroup_0.0  CabinNumGroup_500.0  CabinNumGroup_1000.0  \\\n",
       "0             0                  1                    0                     0   \n",
       "1             1                  1                    0                     0   \n",
       "2             1                  1                    0                     0   \n",
       "3             1                  1                    0                     0   \n",
       "4             1                  1                    0                     0   \n",
       "...         ...                ...                  ...                   ...   \n",
       "8688          0                  1                    0                     0   \n",
       "8689          1                  0                    0                     1   \n",
       "8690          1                  0                    0                     0   \n",
       "8691          1                  0                    1                     0   \n",
       "8692          1                  0                    1                     0   \n",
       "\n",
       "      CabinNumGroup_1500.0  Transported   Age  RoomService  FoodCourt  \\\n",
       "0                        0        False  39.0          0.0        0.0   \n",
       "1                        0         True  24.0        109.0        9.0   \n",
       "2                        0        False  58.0         43.0     3576.0   \n",
       "3                        0        False  33.0          0.0     1283.0   \n",
       "4                        0         True  16.0        303.0       70.0   \n",
       "...                    ...          ...   ...          ...        ...   \n",
       "8688                     0        False  41.0          0.0     6819.0   \n",
       "8689                     0        False  18.0          0.0        0.0   \n",
       "8690                     1         True  26.0          0.0        0.0   \n",
       "8691                     0        False  32.0          0.0     1049.0   \n",
       "8692                     0         True  44.0        126.0     4688.0   \n",
       "\n",
       "      ShoppingMall     Spa  VRDeck  Adult  TotalSpent  \\\n",
       "0              0.0     0.0     0.0      1         0.0   \n",
       "1             25.0   549.0    44.0      1       736.0   \n",
       "2              0.0  6715.0    49.0      1     10383.0   \n",
       "3            371.0  3329.0   193.0      1      5176.0   \n",
       "4            151.0   565.0     2.0      0      1091.0   \n",
       "...            ...     ...     ...    ...         ...   \n",
       "8688           0.0  1643.0    74.0      1      8536.0   \n",
       "8689           0.0     0.0     0.0      1         0.0   \n",
       "8690        1872.0     1.0     0.0      1      1873.0   \n",
       "8691           0.0   353.0  3235.0      1      4637.0   \n",
       "8692           0.0     0.0    12.0      1      4826.0   \n",
       "\n",
       "      TotalSpent_IsZero_Cryo_IsFalse  Ratio_RoomService_TotalSpent  \\\n",
       "0                                  1                           NaN   \n",
       "1                                  0                      0.148098   \n",
       "2                                  0                      0.004141   \n",
       "3                                  0                      0.000000   \n",
       "4                                  0                      0.277727   \n",
       "...                              ...                           ...   \n",
       "8688                               0                      0.000000   \n",
       "8689                               0                           NaN   \n",
       "8690                               0                      0.000000   \n",
       "8691                               0                      0.000000   \n",
       "8692                               0                      0.026109   \n",
       "\n",
       "      Ratio_FoodCourt_TotalSpent  Ratio_ShoppingMall_TotalSpent  \\\n",
       "0                            NaN                            NaN   \n",
       "1                       0.012228                       0.033967   \n",
       "2                       0.344409                       0.000000   \n",
       "3                       0.247875                       0.071677   \n",
       "4                       0.064161                       0.138405   \n",
       "...                          ...                            ...   \n",
       "8688                    0.798852                       0.000000   \n",
       "8689                         NaN                            NaN   \n",
       "8690                    0.000000                       0.999466   \n",
       "8691                    0.226224                       0.000000   \n",
       "8692                    0.971405                       0.000000   \n",
       "\n",
       "      Ratio_Spa_TotalSpent  Ratio_VRDeck_TotalSpent  \n",
       "0                      NaN                      NaN  \n",
       "1                 0.745924                 0.059783  \n",
       "2                 0.646730                 0.004719  \n",
       "3                 0.643161                 0.037287  \n",
       "4                 0.517874                 0.001833  \n",
       "...                    ...                      ...  \n",
       "8688              0.192479                 0.008669  \n",
       "8689                   NaN                      NaN  \n",
       "8690              0.000534                 0.000000  \n",
       "8691              0.076127                 0.697649  \n",
       "8692              0.000000                 0.002487  \n",
       "\n",
       "[8693 rows x 37 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train,test = DataPreparation([train, test],missing_values = True)\n",
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f4385fd3-379d-4e68-b1c7-b003052dfe00",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-06-29 19:10:24,155]\u001b[0m A new study created in memory with name: LGBM Classifier\u001b[0m\n",
      "\u001b[32m[I 2022-06-29 19:10:27,297]\u001b[0m Trial 0 finished with value: 0.8694447429393888 and parameters: {'n_estimators': 10000, 'learning_rate': 0.1457710042989261, 'num_leaves': 245, 'max_depth': 8, 'min_child_samples': 940, 'reg_alpha': 3, 'reg_lambda': 9, 'min_split_gain': 0.0, 'subsample': 0.5, 'subsample_freq': 1, 'colsample_bytree': 0.6000000000000001}. Best is trial 0 with value: 0.8694447429393888.\u001b[0m\n",
      "\u001b[32m[I 2022-06-29 19:10:28,503]\u001b[0m Trial 1 finished with value: 0.8754864864721796 and parameters: {'n_estimators': 10000, 'learning_rate': 0.4266458187758511, 'num_leaves': 250, 'max_depth': 3, 'min_child_samples': 310, 'reg_alpha': 8, 'reg_lambda': 0, 'min_split_gain': 7.0, 'subsample': 0.6000000000000001, 'subsample_freq': 1, 'colsample_bytree': 0.4}. Best is trial 1 with value: 0.8754864864721796.\u001b[0m\n",
      "\u001b[32m[I 2022-06-29 19:10:29,385]\u001b[0m Trial 2 finished with value: 0.883497996672502 and parameters: {'n_estimators': 10000, 'learning_rate': 0.4285173377933425, 'num_leaves': 210, 'max_depth': 7, 'min_child_samples': 80, 'reg_alpha': 5, 'reg_lambda': 3, 'min_split_gain': 8.0, 'subsample': 0.8, 'subsample_freq': 1, 'colsample_bytree': 0.9}. Best is trial 2 with value: 0.883497996672502.\u001b[0m\n",
      "\u001b[32m[I 2022-06-29 19:10:31,755]\u001b[0m Trial 3 finished with value: 0.8750565478821476 and parameters: {'n_estimators': 10000, 'learning_rate': 0.09654477299812526, 'num_leaves': 235, 'max_depth': 6, 'min_child_samples': 150, 'reg_alpha': 3, 'reg_lambda': 5, 'min_split_gain': 10.5, 'subsample': 0.4, 'subsample_freq': 1, 'colsample_bytree': 0.6000000000000001}. Best is trial 2 with value: 0.883497996672502.\u001b[0m\n",
      "\u001b[32m[I 2022-06-29 19:10:32,907]\u001b[0m Trial 4 finished with value: 0.8632944825253414 and parameters: {'n_estimators': 10000, 'learning_rate': 0.22572495080932597, 'num_leaves': 80, 'max_depth': 5, 'min_child_samples': 580, 'reg_alpha': 5, 'reg_lambda': 2, 'min_split_gain': 14.5, 'subsample': 0.4, 'subsample_freq': 1, 'colsample_bytree': 0.5}. Best is trial 2 with value: 0.883497996672502.\u001b[0m\n",
      "\u001b[32m[I 2022-06-29 19:10:33,752]\u001b[0m Trial 5 finished with value: 0.8776343796301638 and parameters: {'n_estimators': 10000, 'learning_rate': 0.3934820015197717, 'num_leaves': 55, 'max_depth': 7, 'min_child_samples': 230, 'reg_alpha': 5, 'reg_lambda': 7, 'min_split_gain': 7.5, 'subsample': 0.6000000000000001, 'subsample_freq': 1, 'colsample_bytree': 0.7000000000000001}. Best is trial 2 with value: 0.883497996672502.\u001b[0m\n",
      "\u001b[32m[I 2022-06-29 19:10:34,655]\u001b[0m Trial 6 finished with value: 0.8764245222742808 and parameters: {'n_estimators': 10000, 'learning_rate': 0.37569185729326704, 'num_leaves': 205, 'max_depth': 3, 'min_child_samples': 330, 'reg_alpha': 1, 'reg_lambda': 4, 'min_split_gain': 14.0, 'subsample': 0.8, 'subsample_freq': 1, 'colsample_bytree': 0.6000000000000001}. Best is trial 2 with value: 0.883497996672502.\u001b[0m\n",
      "\u001b[32m[I 2022-06-29 19:10:36,106]\u001b[0m Trial 7 finished with value: 0.8694860322893303 and parameters: {'n_estimators': 10000, 'learning_rate': 0.10913261770753108, 'num_leaves': 130, 'max_depth': 9, 'min_child_samples': 460, 'reg_alpha': 9, 'reg_lambda': 8, 'min_split_gain': 12.5, 'subsample': 0.8, 'subsample_freq': 1, 'colsample_bytree': 0.6000000000000001}. Best is trial 2 with value: 0.883497996672502.\u001b[0m\n",
      "\u001b[32m[I 2022-06-29 19:10:37,764]\u001b[0m Trial 8 finished with value: 0.8706900932557022 and parameters: {'n_estimators': 10000, 'learning_rate': 0.17225449244282842, 'num_leaves': 105, 'max_depth': 5, 'min_child_samples': 730, 'reg_alpha': 7, 'reg_lambda': 0, 'min_split_gain': 7.0, 'subsample': 0.7000000000000001, 'subsample_freq': 1, 'colsample_bytree': 0.4}. Best is trial 2 with value: 0.883497996672502.\u001b[0m\n",
      "\u001b[32m[I 2022-06-29 19:10:39,114]\u001b[0m Trial 9 finished with value: 0.8761536270841196 and parameters: {'n_estimators': 10000, 'learning_rate': 0.17841074267866297, 'num_leaves': 250, 'max_depth': 3, 'min_child_samples': 310, 'reg_alpha': 9, 'reg_lambda': 1, 'min_split_gain': 8.0, 'subsample': 0.9, 'subsample_freq': 1, 'colsample_bytree': 0.5}. Best is trial 2 with value: 0.883497996672502.\u001b[0m\n",
      "\u001b[32m[I 2022-06-29 19:10:39,840]\u001b[0m Trial 10 finished with value: 0.8888218348669503 and parameters: {'n_estimators': 10000, 'learning_rate': 0.4956441907162753, 'num_leaves': 165, 'max_depth': 10, 'min_child_samples': 110, 'reg_alpha': 0, 'reg_lambda': 3, 'min_split_gain': 3.0, 'subsample': 0.9, 'subsample_freq': 1, 'colsample_bytree': 0.9}. Best is trial 10 with value: 0.8888218348669503.\u001b[0m\n",
      "\u001b[32m[I 2022-06-29 19:10:40,503]\u001b[0m Trial 11 finished with value: 0.8898372087975959 and parameters: {'n_estimators': 10000, 'learning_rate': 0.4894560440501324, 'num_leaves': 180, 'max_depth': 10, 'min_child_samples': 60, 'reg_alpha': 0, 'reg_lambda': 3, 'min_split_gain': 3.0, 'subsample': 0.9, 'subsample_freq': 1, 'colsample_bytree': 0.9}. Best is trial 11 with value: 0.8898372087975959.\u001b[0m\n",
      "\u001b[32m[I 2022-06-29 19:10:41,172]\u001b[0m Trial 12 finished with value: 0.8894258768825696 and parameters: {'n_estimators': 10000, 'learning_rate': 0.4944642908590114, 'num_leaves': 160, 'max_depth': 10, 'min_child_samples': 50, 'reg_alpha': 0, 'reg_lambda': 5, 'min_split_gain': 2.0, 'subsample': 0.9, 'subsample_freq': 1, 'colsample_bytree': 0.9}. Best is trial 11 with value: 0.8898372087975959.\u001b[0m\n",
      "\u001b[32m[I 2022-06-29 19:10:42,279]\u001b[0m Trial 13 finished with value: 0.889760717630076 and parameters: {'n_estimators': 10000, 'learning_rate': 0.3292248668218586, 'num_leaves': 165, 'max_depth': 10, 'min_child_samples': 50, 'reg_alpha': 1, 'reg_lambda': 5, 'min_split_gain': 2.5, 'subsample': 0.9, 'subsample_freq': 1, 'colsample_bytree': 0.8}. Best is trial 11 with value: 0.8898372087975959.\u001b[0m\n",
      "\u001b[32m[I 2022-06-29 19:10:43,186]\u001b[0m Trial 14 finished with value: 0.8777865150041791 and parameters: {'n_estimators': 10000, 'learning_rate': 0.31163356178359974, 'num_leaves': 180, 'max_depth': 9, 'min_child_samples': 530, 'reg_alpha': 2, 'reg_lambda': 6, 'min_split_gain': 4.0, 'subsample': 0.7000000000000001, 'subsample_freq': 1, 'colsample_bytree': 0.8}. Best is trial 11 with value: 0.8898372087975959.\u001b[0m\n",
      "\u001b[32m[I 2022-06-29 19:10:44,315]\u001b[0m Trial 15 finished with value: 0.8869127053152627 and parameters: {'n_estimators': 10000, 'learning_rate': 0.3033774565662874, 'num_leaves': 130, 'max_depth': 9, 'min_child_samples': 210, 'reg_alpha': 2, 'reg_lambda': 3, 'min_split_gain': 4.5, 'subsample': 0.9, 'subsample_freq': 1, 'colsample_bytree': 0.8}. Best is trial 11 with value: 0.8898372087975959.\u001b[0m\n",
      "\u001b[32m[I 2022-06-29 19:10:50,274]\u001b[0m Trial 16 finished with value: 0.8873253606068899 and parameters: {'n_estimators': 10000, 'learning_rate': 0.016979412002176286, 'num_leaves': 185, 'max_depth': 10, 'min_child_samples': 420, 'reg_alpha': 3, 'reg_lambda': 6, 'min_split_gain': 0.5, 'subsample': 0.8, 'subsample_freq': 1, 'colsample_bytree': 0.8}. Best is trial 11 with value: 0.8898372087975959.\u001b[0m\n",
      "\u001b[32m[I 2022-06-29 19:10:51,600]\u001b[0m Trial 17 finished with value: 0.8759655488016295 and parameters: {'n_estimators': 10000, 'learning_rate': 0.3146246569951554, 'num_leaves': 140, 'max_depth': 8, 'min_child_samples': 670, 'reg_alpha': 1, 'reg_lambda': 3, 'min_split_gain': 5.0, 'subsample': 0.7000000000000001, 'subsample_freq': 1, 'colsample_bytree': 0.7000000000000001}. Best is trial 11 with value: 0.8898372087975959.\u001b[0m\n",
      "\u001b[32m[I 2022-06-29 19:10:52,591]\u001b[0m Trial 18 finished with value: 0.8747950486658511 and parameters: {'n_estimators': 10000, 'learning_rate': 0.3630298218291022, 'num_leaves': 215, 'max_depth': 8, 'min_child_samples': 970, 'reg_alpha': 6, 'reg_lambda': 6, 'min_split_gain': 2.0, 'subsample': 0.9, 'subsample_freq': 1, 'colsample_bytree': 0.8}. Best is trial 11 with value: 0.8898372087975959.\u001b[0m\n",
      "\u001b[32m[I 2022-06-29 19:10:53,840]\u001b[0m Trial 19 finished with value: 0.8843784655924731 and parameters: {'n_estimators': 10000, 'learning_rate': 0.2333682384658691, 'num_leaves': 110, 'max_depth': 10, 'min_child_samples': 200, 'reg_alpha': 3, 'reg_lambda': 4, 'min_split_gain': 5.5, 'subsample': 0.8, 'subsample_freq': 1, 'colsample_bytree': 0.9}. Best is trial 11 with value: 0.8898372087975959.\u001b[0m\n",
      "\u001b[32m[I 2022-06-29 19:10:55,291]\u001b[0m Trial 20 finished with value: 0.8834144122064023 and parameters: {'n_estimators': 10000, 'learning_rate': 0.45580172900907445, 'num_leaves': 190, 'max_depth': 9, 'min_child_samples': 50, 'reg_alpha': 1, 'reg_lambda': 1, 'min_split_gain': 10.0, 'subsample': 0.5, 'subsample_freq': 1, 'colsample_bytree': 0.7000000000000001}. Best is trial 11 with value: 0.8898372087975959.\u001b[0m\n",
      "\u001b[32m[I 2022-06-29 19:10:55,932]\u001b[0m Trial 21 finished with value: 0.8895587968283427 and parameters: {'n_estimators': 10000, 'learning_rate': 0.4655318269602237, 'num_leaves': 160, 'max_depth': 10, 'min_child_samples': 50, 'reg_alpha': 0, 'reg_lambda': 4, 'min_split_gain': 2.0, 'subsample': 0.9, 'subsample_freq': 1, 'colsample_bytree': 0.9}. Best is trial 11 with value: 0.8898372087975959.\u001b[0m\n",
      "\u001b[32m[I 2022-06-29 19:10:56,735]\u001b[0m Trial 22 finished with value: 0.8902534636735769 and parameters: {'n_estimators': 10000, 'learning_rate': 0.4534703473362599, 'num_leaves': 155, 'max_depth': 10, 'min_child_samples': 160, 'reg_alpha': 1, 'reg_lambda': 4, 'min_split_gain': 1.5, 'subsample': 0.9, 'subsample_freq': 1, 'colsample_bytree': 0.9}. Best is trial 22 with value: 0.8902534636735769.\u001b[0m\n",
      "\u001b[32m[I 2022-06-29 19:10:57,590]\u001b[0m Trial 23 finished with value: 0.8918951652817971 and parameters: {'n_estimators': 10000, 'learning_rate': 0.3510603690576052, 'num_leaves': 145, 'max_depth': 9, 'min_child_samples': 170, 'reg_alpha': 1, 'reg_lambda': 4, 'min_split_gain': 1.0, 'subsample': 0.8, 'subsample_freq': 1, 'colsample_bytree': 0.8}. Best is trial 23 with value: 0.8918951652817971.\u001b[0m\n",
      "\u001b[32m[I 2022-06-29 19:10:58,524]\u001b[0m Trial 24 finished with value: 0.8895475481272368 and parameters: {'n_estimators': 10000, 'learning_rate': 0.40205311085620415, 'num_leaves': 115, 'max_depth': 9, 'min_child_samples': 270, 'reg_alpha': 2, 'reg_lambda': 1, 'min_split_gain': 1.0, 'subsample': 0.8, 'subsample_freq': 1, 'colsample_bytree': 0.9}. Best is trial 23 with value: 0.8918951652817971.\u001b[0m\n",
      "\u001b[32m[I 2022-06-29 19:10:59,400]\u001b[0m Trial 25 finished with value: 0.8867699129800481 and parameters: {'n_estimators': 10000, 'learning_rate': 0.4457523989674306, 'num_leaves': 135, 'max_depth': 8, 'min_child_samples': 160, 'reg_alpha': 3, 'reg_lambda': 2, 'min_split_gain': 3.5, 'subsample': 0.8, 'subsample_freq': 1, 'colsample_bytree': 0.8}. Best is trial 23 with value: 0.8918951652817971.\u001b[0m\n",
      "\u001b[32m[I 2022-06-29 19:11:00,649]\u001b[0m Trial 26 finished with value: 0.8840684513899955 and parameters: {'n_estimators': 10000, 'learning_rate': 0.49995515913194344, 'num_leaves': 145, 'max_depth': 9, 'min_child_samples': 390, 'reg_alpha': 4, 'reg_lambda': 3, 'min_split_gain': 1.0, 'subsample': 0.7000000000000001, 'subsample_freq': 1, 'colsample_bytree': 0.9}. Best is trial 23 with value: 0.8918951652817971.\u001b[0m\n",
      "\u001b[32m[I 2022-06-29 19:11:01,582]\u001b[0m Trial 27 finished with value: 0.8854523857039331 and parameters: {'n_estimators': 10000, 'learning_rate': 0.34824555254490636, 'num_leaves': 175, 'max_depth': 7, 'min_child_samples': 170, 'reg_alpha': 1, 'reg_lambda': 4, 'min_split_gain': 6.0, 'subsample': 0.9, 'subsample_freq': 1, 'colsample_bytree': 0.8}. Best is trial 23 with value: 0.8918951652817971.\u001b[0m\n",
      "\u001b[32m[I 2022-06-29 19:11:03,501]\u001b[0m Trial 28 finished with value: 0.8860093684476316 and parameters: {'n_estimators': 10000, 'learning_rate': 0.2876881093593397, 'num_leaves': 195, 'max_depth': 10, 'min_child_samples': 880, 'reg_alpha': 1, 'reg_lambda': 4, 'min_split_gain': 0.0, 'subsample': 0.8, 'subsample_freq': 1, 'colsample_bytree': 0.7000000000000001}. Best is trial 23 with value: 0.8918951652817971.\u001b[0m\n",
      "\u001b[32m[I 2022-06-29 19:11:04,720]\u001b[0m Trial 29 finished with value: 0.8918173507376765 and parameters: {'n_estimators': 10000, 'learning_rate': 0.41160783431000364, 'num_leaves': 150, 'max_depth': 8, 'min_child_samples': 250, 'reg_alpha': 4, 'reg_lambda': 9, 'min_split_gain': 0.0, 'subsample': 0.9, 'subsample_freq': 1, 'colsample_bytree': 0.9}. Best is trial 23 with value: 0.8918951652817971.\u001b[0m\n",
      "\u001b[32m[I 2022-06-29 19:11:05,925]\u001b[0m Trial 30 finished with value: 0.8866540116573598 and parameters: {'n_estimators': 10000, 'learning_rate': 0.40563878253335883, 'num_leaves': 85, 'max_depth': 8, 'min_child_samples': 390, 'reg_alpha': 4, 'reg_lambda': 9, 'min_split_gain': 0.0, 'subsample': 0.6000000000000001, 'subsample_freq': 1, 'colsample_bytree': 0.8}. Best is trial 23 with value: 0.8918951652817971.\u001b[0m\n",
      "\u001b[32m[I 2022-06-29 19:11:06,578]\u001b[0m Trial 31 finished with value: 0.8906783734325265 and parameters: {'n_estimators': 10000, 'learning_rate': 0.4497709962101391, 'num_leaves': 150, 'max_depth': 8, 'min_child_samples': 130, 'reg_alpha': 1, 'reg_lambda': 9, 'min_split_gain': 1.5, 'subsample': 0.9, 'subsample_freq': 1, 'colsample_bytree': 0.9}. Best is trial 23 with value: 0.8918951652817971.\u001b[0m\n",
      "\u001b[32m[I 2022-06-29 19:11:07,452]\u001b[0m Trial 32 finished with value: 0.8866403808783727 and parameters: {'n_estimators': 10000, 'learning_rate': 0.4234397432489097, 'num_leaves': 150, 'max_depth': 6, 'min_child_samples': 270, 'reg_alpha': 1, 'reg_lambda': 9, 'min_split_gain': 1.5, 'subsample': 0.9, 'subsample_freq': 1, 'colsample_bytree': 0.9}. Best is trial 23 with value: 0.8918951652817971.\u001b[0m\n",
      "\u001b[32m[I 2022-06-29 19:11:08,919]\u001b[0m Trial 33 finished with value: 0.8928391562786014 and parameters: {'n_estimators': 10000, 'learning_rate': 0.26691027454913085, 'num_leaves': 120, 'max_depth': 7, 'min_child_samples': 130, 'reg_alpha': 3, 'reg_lambda': 8, 'min_split_gain': 0.0, 'subsample': 0.8, 'subsample_freq': 1, 'colsample_bytree': 0.9}. Best is trial 33 with value: 0.8928391562786014.\u001b[0m\n",
      "\u001b[32m[I 2022-06-29 19:11:10,435]\u001b[0m Trial 34 finished with value: 0.8927687791109767 and parameters: {'n_estimators': 10000, 'learning_rate': 0.27626570008869644, 'num_leaves': 120, 'max_depth': 7, 'min_child_samples': 110, 'reg_alpha': 4, 'reg_lambda': 9, 'min_split_gain': 0.0, 'subsample': 0.7000000000000001, 'subsample_freq': 1, 'colsample_bytree': 0.9}. Best is trial 33 with value: 0.8928391562786014.\u001b[0m\n",
      "\u001b[32m[I 2022-06-29 19:11:11,865]\u001b[0m Trial 35 finished with value: 0.8910875085423958 and parameters: {'n_estimators': 10000, 'learning_rate': 0.2682409937736711, 'num_leaves': 100, 'max_depth': 7, 'min_child_samples': 250, 'reg_alpha': 4, 'reg_lambda': 9, 'min_split_gain': 0.0, 'subsample': 0.7000000000000001, 'subsample_freq': 1, 'colsample_bytree': 0.8}. Best is trial 33 with value: 0.8928391562786014.\u001b[0m\n",
      "\u001b[32m[I 2022-06-29 19:11:13,327]\u001b[0m Trial 36 finished with value: 0.8896247539181211 and parameters: {'n_estimators': 10000, 'learning_rate': 0.2444123883946285, 'num_leaves': 120, 'max_depth': 6, 'min_child_samples': 340, 'reg_alpha': 4, 'reg_lambda': 9, 'min_split_gain': 0.0, 'subsample': 0.7000000000000001, 'subsample_freq': 1, 'colsample_bytree': 0.9}. Best is trial 33 with value: 0.8928391562786014.\u001b[0m\n",
      "\u001b[32m[I 2022-06-29 19:11:14,770]\u001b[0m Trial 37 finished with value: 0.8894888166736982 and parameters: {'n_estimators': 10000, 'learning_rate': 0.2102297556269037, 'num_leaves': 80, 'max_depth': 7, 'min_child_samples': 120, 'reg_alpha': 5, 'reg_lambda': 9, 'min_split_gain': 1.0, 'subsample': 0.6000000000000001, 'subsample_freq': 1, 'colsample_bytree': 0.9}. Best is trial 33 with value: 0.8928391562786014.\u001b[0m\n",
      "\u001b[32m[I 2022-06-29 19:11:16,011]\u001b[0m Trial 38 finished with value: 0.8731438981487021 and parameters: {'n_estimators': 10000, 'learning_rate': 0.34135466140447795, 'num_leaves': 55, 'max_depth': 5, 'min_child_samples': 230, 'reg_alpha': 6, 'reg_lambda': 9, 'min_split_gain': 9.5, 'subsample': 0.5, 'subsample_freq': 1, 'colsample_bytree': 0.7000000000000001}. Best is trial 33 with value: 0.8928391562786014.\u001b[0m\n",
      "\u001b[32m[I 2022-06-29 19:11:17,239]\u001b[0m Trial 39 finished with value: 0.8882487598637875 and parameters: {'n_estimators': 10000, 'learning_rate': 0.28044124803466514, 'num_leaves': 100, 'max_depth': 6, 'min_child_samples': 110, 'reg_alpha': 5, 'reg_lambda': 9, 'min_split_gain': 3.0, 'subsample': 0.8, 'subsample_freq': 1, 'colsample_bytree': 0.8}. Best is trial 33 with value: 0.8928391562786014.\u001b[0m\n",
      "\u001b[32m[I 2022-06-29 19:11:18,062]\u001b[0m Trial 40 finished with value: 0.8729986178654783 and parameters: {'n_estimators': 10000, 'learning_rate': 0.3767689664862083, 'num_leaves': 120, 'max_depth': 4, 'min_child_samples': 470, 'reg_alpha': 3, 'reg_lambda': 9, 'min_split_gain': 11.5, 'subsample': 0.8, 'subsample_freq': 1, 'colsample_bytree': 0.5}. Best is trial 33 with value: 0.8928391562786014.\u001b[0m\n",
      "\u001b[32m[I 2022-06-29 19:11:19,380]\u001b[0m Trial 41 finished with value: 0.8905010145005021 and parameters: {'n_estimators': 10000, 'learning_rate': 0.27075842064515077, 'num_leaves': 90, 'max_depth': 7, 'min_child_samples': 270, 'reg_alpha': 4, 'reg_lambda': 7, 'min_split_gain': 0.0, 'subsample': 0.7000000000000001, 'subsample_freq': 1, 'colsample_bytree': 0.8}. Best is trial 33 with value: 0.8928391562786014.\u001b[0m\n",
      "\u001b[32m[I 2022-06-29 19:11:20,614]\u001b[0m Trial 42 finished with value: 0.89001417071664 and parameters: {'n_estimators': 10000, 'learning_rate': 0.2033077323900952, 'num_leaves': 70, 'max_depth': 7, 'min_child_samples': 230, 'reg_alpha': 3, 'reg_lambda': 9, 'min_split_gain': 0.5, 'subsample': 0.7000000000000001, 'subsample_freq': 1, 'colsample_bytree': 0.9}. Best is trial 33 with value: 0.8928391562786014.\u001b[0m\n",
      "\u001b[32m[I 2022-06-29 19:11:21,881]\u001b[0m Trial 43 finished with value: 0.8869284270292789 and parameters: {'n_estimators': 10000, 'learning_rate': 0.26045621050510726, 'num_leaves': 95, 'max_depth': 7, 'min_child_samples': 350, 'reg_alpha': 3, 'reg_lambda': 9, 'min_split_gain': 0.5, 'subsample': 0.6000000000000001, 'subsample_freq': 1, 'colsample_bytree': 0.8}. Best is trial 33 with value: 0.8928391562786014.\u001b[0m\n",
      "\u001b[32m[I 2022-06-29 19:11:23,933]\u001b[0m Trial 44 finished with value: 0.8861511285490976 and parameters: {'n_estimators': 10000, 'learning_rate': 0.12779569176860506, 'num_leaves': 125, 'max_depth': 8, 'min_child_samples': 300, 'reg_alpha': 4, 'reg_lambda': 8, 'min_split_gain': 1.0, 'subsample': 0.7000000000000001, 'subsample_freq': 1, 'colsample_bytree': 0.7000000000000001}. Best is trial 33 with value: 0.8928391562786014.\u001b[0m\n",
      "\u001b[32m[I 2022-06-29 19:11:25,192]\u001b[0m Trial 45 finished with value: 0.8872892059581591 and parameters: {'n_estimators': 10000, 'learning_rate': 0.17487480961552965, 'num_leaves': 105, 'max_depth': 6, 'min_child_samples': 190, 'reg_alpha': 3, 'reg_lambda': 9, 'min_split_gain': 2.5, 'subsample': 0.8, 'subsample_freq': 1, 'colsample_bytree': 0.9}. Best is trial 33 with value: 0.8928391562786014.\u001b[0m\n",
      "\u001b[32m[I 2022-06-29 19:11:26,815]\u001b[0m Trial 46 finished with value: 0.8931057901961086 and parameters: {'n_estimators': 10000, 'learning_rate': 0.2943061995980123, 'num_leaves': 135, 'max_depth': 7, 'min_child_samples': 110, 'reg_alpha': 6, 'reg_lambda': 8, 'min_split_gain': 0.0, 'subsample': 0.8, 'subsample_freq': 1, 'colsample_bytree': 0.8}. Best is trial 46 with value: 0.8931057901961086.\u001b[0m\n",
      "\u001b[32m[I 2022-06-29 19:11:28,126]\u001b[0m Trial 47 finished with value: 0.8855476688191829 and parameters: {'n_estimators': 10000, 'learning_rate': 0.2926408635601485, 'num_leaves': 140, 'max_depth': 8, 'min_child_samples': 90, 'reg_alpha': 5, 'reg_lambda': 9, 'min_split_gain': 4.0, 'subsample': 0.8, 'subsample_freq': 1, 'colsample_bytree': 0.6000000000000001}. Best is trial 46 with value: 0.8931057901961086.\u001b[0m\n",
      "\u001b[32m[I 2022-06-29 19:11:29,091]\u001b[0m Trial 48 finished with value: 0.8887389650242151 and parameters: {'n_estimators': 10000, 'learning_rate': 0.3272723901261909, 'num_leaves': 170, 'max_depth': 7, 'min_child_samples': 100, 'reg_alpha': 5, 'reg_lambda': 9, 'min_split_gain': 2.5, 'subsample': 0.8, 'subsample_freq': 1, 'colsample_bytree': 0.9}. Best is trial 46 with value: 0.8931057901961086.\u001b[0m\n",
      "\u001b[32m[I 2022-06-29 19:11:31,198]\u001b[0m Trial 49 finished with value: 0.8857257423745717 and parameters: {'n_estimators': 10000, 'learning_rate': 0.2118698851088383, 'num_leaves': 135, 'max_depth': 8, 'min_child_samples': 140, 'reg_alpha': 5, 'reg_lambda': 9, 'min_split_gain': 1.5, 'subsample': 0.4, 'subsample_freq': 1, 'colsample_bytree': 0.9}. Best is trial 46 with value: 0.8931057901961086.\u001b[0m\n",
      "\u001b[32m[I 2022-06-29 19:11:32,800]\u001b[0m Trial 50 finished with value: 0.8828857761894906 and parameters: {'n_estimators': 10000, 'learning_rate': 0.36901184570537704, 'num_leaves': 125, 'max_depth': 6, 'min_child_samples': 660, 'reg_alpha': 6, 'reg_lambda': 9, 'min_split_gain': 0.5, 'subsample': 0.8, 'subsample_freq': 1, 'colsample_bytree': 0.8}. Best is trial 46 with value: 0.8931057901961086.\u001b[0m\n",
      "\u001b[32m[I 2022-06-29 19:11:34,339]\u001b[0m Trial 51 finished with value: 0.88983358274571 and parameters: {'n_estimators': 10000, 'learning_rate': 0.25334831648207057, 'num_leaves': 70, 'max_depth': 7, 'min_child_samples': 250, 'reg_alpha': 6, 'reg_lambda': 9, 'min_split_gain': 0.0, 'subsample': 0.7000000000000001, 'subsample_freq': 1, 'colsample_bytree': 0.8}. Best is trial 46 with value: 0.8931057901961086.\u001b[0m\n",
      "\u001b[32m[I 2022-06-29 19:11:35,280]\u001b[0m Trial 52 finished with value: 0.8892550024958883 and parameters: {'n_estimators': 10000, 'learning_rate': 0.27070604023813216, 'num_leaves': 110, 'max_depth': 7, 'min_child_samples': 200, 'reg_alpha': 4, 'reg_lambda': 9, 'min_split_gain': 1.0, 'subsample': 0.7000000000000001, 'subsample_freq': 1, 'colsample_bytree': 0.8}. Best is trial 46 with value: 0.8931057901961086.\u001b[0m\n",
      "\u001b[32m[I 2022-06-29 19:11:36,749]\u001b[0m Trial 53 finished with value: 0.8921886372767663 and parameters: {'n_estimators': 10000, 'learning_rate': 0.30305429573281484, 'num_leaves': 130, 'max_depth': 8, 'min_child_samples': 90, 'reg_alpha': 4, 'reg_lambda': 9, 'min_split_gain': 0.0, 'subsample': 0.7000000000000001, 'subsample_freq': 1, 'colsample_bytree': 0.4}. Best is trial 46 with value: 0.8931057901961086.\u001b[0m\n",
      "\u001b[32m[I 2022-06-29 19:11:37,916]\u001b[0m Trial 54 finished with value: 0.8859625209159672 and parameters: {'n_estimators': 10000, 'learning_rate': 0.3209110175106681, 'num_leaves': 130, 'max_depth': 9, 'min_child_samples': 90, 'reg_alpha': 6, 'reg_lambda': 9, 'min_split_gain': 2.0, 'subsample': 0.6000000000000001, 'subsample_freq': 1, 'colsample_bytree': 0.4}. Best is trial 46 with value: 0.8931057901961086.\u001b[0m\n",
      "\u001b[32m[I 2022-06-29 19:11:38,985]\u001b[0m Trial 55 finished with value: 0.8779063070540737 and parameters: {'n_estimators': 10000, 'learning_rate': 0.34990766228273806, 'num_leaves': 145, 'max_depth': 8, 'min_child_samples': 160, 'reg_alpha': 3, 'reg_lambda': 9, 'min_split_gain': 13.0, 'subsample': 0.8, 'subsample_freq': 1, 'colsample_bytree': 0.4}. Best is trial 46 with value: 0.8931057901961086.\u001b[0m\n",
      "\u001b[32m[I 2022-06-29 19:11:39,998]\u001b[0m Trial 56 finished with value: 0.8920396780065925 and parameters: {'n_estimators': 10000, 'learning_rate': 0.29846552029573853, 'num_leaves': 155, 'max_depth': 9, 'min_child_samples': 90, 'reg_alpha': 4, 'reg_lambda': 9, 'min_split_gain': 0.5, 'subsample': 0.7000000000000001, 'subsample_freq': 1, 'colsample_bytree': 0.5}. Best is trial 46 with value: 0.8931057901961086.\u001b[0m\n",
      "\u001b[32m[I 2022-06-29 19:11:41,867]\u001b[0m Trial 57 finished with value: 0.8859860770194595 and parameters: {'n_estimators': 10000, 'learning_rate': 0.30190677530534554, 'num_leaves': 160, 'max_depth': 9, 'min_child_samples': 80, 'reg_alpha': 6, 'reg_lambda': 9, 'min_split_gain': 3.5, 'subsample': 0.7000000000000001, 'subsample_freq': 1, 'colsample_bytree': 0.5}. Best is trial 46 with value: 0.8931057901961086.\u001b[0m\n",
      "\u001b[32m[I 2022-06-29 19:11:43,008]\u001b[0m Trial 58 finished with value: 0.8883107732912959 and parameters: {'n_estimators': 10000, 'learning_rate': 0.30547317142842995, 'num_leaves': 115, 'max_depth': 9, 'min_child_samples': 140, 'reg_alpha': 4, 'reg_lambda': 9, 'min_split_gain': 2.0, 'subsample': 0.7000000000000001, 'subsample_freq': 1, 'colsample_bytree': 0.5}. Best is trial 46 with value: 0.8931057901961086.\u001b[0m\n",
      "\u001b[32m[I 2022-06-29 19:11:44,809]\u001b[0m Trial 59 finished with value: 0.8786728861837895 and parameters: {'n_estimators': 10000, 'learning_rate': 0.2302734232962454, 'num_leaves': 140, 'max_depth': 9, 'min_child_samples': 180, 'reg_alpha': 4, 'reg_lambda': 9, 'min_split_gain': 9.0, 'subsample': 0.7000000000000001, 'subsample_freq': 1, 'colsample_bytree': 0.4}. Best is trial 46 with value: 0.8931057901961086.\u001b[0m\n",
      "\u001b[32m[I 2022-06-29 19:11:46,309]\u001b[0m Trial 60 finished with value: 0.8909538739732583 and parameters: {'n_estimators': 10000, 'learning_rate': 0.3845814649680366, 'num_leaves': 125, 'max_depth': 8, 'min_child_samples': 70, 'reg_alpha': 7, 'reg_lambda': 9, 'min_split_gain': 0.5, 'subsample': 0.8, 'subsample_freq': 1, 'colsample_bytree': 0.5}. Best is trial 46 with value: 0.8931057901961086.\u001b[0m\n",
      "\u001b[32m[I 2022-06-29 19:11:47,399]\u001b[0m Trial 61 finished with value: 0.8896779007224048 and parameters: {'n_estimators': 10000, 'learning_rate': 0.33538933226563106, 'num_leaves': 155, 'max_depth': 8, 'min_child_samples': 120, 'reg_alpha': 4, 'reg_lambda': 9, 'min_split_gain': 1.0, 'subsample': 0.6000000000000001, 'subsample_freq': 1, 'colsample_bytree': 0.6000000000000001}. Best is trial 46 with value: 0.8931057901961086.\u001b[0m\n",
      "\u001b[32m[I 2022-06-29 19:11:48,547]\u001b[0m Trial 62 finished with value: 0.8640393847463379 and parameters: {'n_estimators': 10000, 'learning_rate': 0.35875622286289766, 'num_leaves': 170, 'max_depth': 8, 'min_child_samples': 860, 'reg_alpha': 4, 'reg_lambda': 9, 'min_split_gain': 15.0, 'subsample': 0.8, 'subsample_freq': 1, 'colsample_bytree': 0.4}. Best is trial 46 with value: 0.8931057901961086.\u001b[0m\n",
      "\u001b[32m[I 2022-06-29 19:11:49,534]\u001b[0m Trial 63 finished with value: 0.8920549233050324 and parameters: {'n_estimators': 10000, 'learning_rate': 0.2891339613256429, 'num_leaves': 135, 'max_depth': 9, 'min_child_samples': 50, 'reg_alpha': 4, 'reg_lambda': 9, 'min_split_gain': 0.5, 'subsample': 0.9, 'subsample_freq': 1, 'colsample_bytree': 0.7000000000000001}. Best is trial 46 with value: 0.8931057901961086.\u001b[0m\n",
      "\u001b[32m[I 2022-06-29 19:11:50,649]\u001b[0m Trial 64 finished with value: 0.8922160047048686 and parameters: {'n_estimators': 10000, 'learning_rate': 0.24713539050446384, 'num_leaves': 135, 'max_depth': 9, 'min_child_samples': 60, 'reg_alpha': 4, 'reg_lambda': 9, 'min_split_gain': 0.5, 'subsample': 0.8, 'subsample_freq': 1, 'colsample_bytree': 0.7000000000000001}. Best is trial 46 with value: 0.8931057901961086.\u001b[0m\n",
      "\u001b[32m[I 2022-06-29 19:11:51,847]\u001b[0m Trial 65 finished with value: 0.8901071246890726 and parameters: {'n_estimators': 10000, 'learning_rate': 0.2430449619378971, 'num_leaves': 135, 'max_depth': 9, 'min_child_samples': 50, 'reg_alpha': 3, 'reg_lambda': 9, 'min_split_gain': 2.5, 'subsample': 0.7000000000000001, 'subsample_freq': 1, 'colsample_bytree': 0.7000000000000001}. Best is trial 46 with value: 0.8931057901961086.\u001b[0m\n",
      "\u001b[32m[I 2022-06-29 19:11:53,078]\u001b[0m Trial 66 finished with value: 0.8906801996922356 and parameters: {'n_estimators': 10000, 'learning_rate': 0.28906381999295, 'num_leaves': 115, 'max_depth': 5, 'min_child_samples': 80, 'reg_alpha': 3, 'reg_lambda': 9, 'min_split_gain': 1.5, 'subsample': 0.7000000000000001, 'subsample_freq': 1, 'colsample_bytree': 0.6000000000000001}. Best is trial 46 with value: 0.8931057901961086.\u001b[0m\n",
      "\u001b[32m[I 2022-06-29 19:11:54,281]\u001b[0m Trial 67 finished with value: 0.8910366908809295 and parameters: {'n_estimators': 10000, 'learning_rate': 0.20093005250623197, 'num_leaves': 130, 'max_depth': 10, 'min_child_samples': 110, 'reg_alpha': 3, 'reg_lambda': 9, 'min_split_gain': 0.5, 'subsample': 0.9, 'subsample_freq': 1, 'colsample_bytree': 0.7000000000000001}. Best is trial 46 with value: 0.8931057901961086.\u001b[0m\n",
      "\u001b[32m[I 2022-06-29 19:11:57,596]\u001b[0m Trial 68 finished with value: 0.8898655819919147 and parameters: {'n_estimators': 10000, 'learning_rate': 0.036732749363198924, 'num_leaves': 240, 'max_depth': 9, 'min_child_samples': 130, 'reg_alpha': 3, 'reg_lambda': 9, 'min_split_gain': 1.5, 'subsample': 0.6000000000000001, 'subsample_freq': 1, 'colsample_bytree': 0.6000000000000001}. Best is trial 46 with value: 0.8931057901961086.\u001b[0m\n",
      "\u001b[32m[I 2022-06-29 19:11:58,760]\u001b[0m Trial 69 finished with value: 0.8926511838662394 and parameters: {'n_estimators': 10000, 'learning_rate': 0.2532448289610205, 'num_leaves': 110, 'max_depth': 7, 'min_child_samples': 60, 'reg_alpha': 3, 'reg_lambda': 8, 'min_split_gain': 0.5, 'subsample': 0.8, 'subsample_freq': 1, 'colsample_bytree': 0.7000000000000001}. Best is trial 46 with value: 0.8931057901961086.\u001b[0m\n",
      "\u001b[32m[I 2022-06-29 19:12:00,562]\u001b[0m Trial 70 finished with value: 0.8942222171639829 and parameters: {'n_estimators': 10000, 'learning_rate': 0.22540272995768512, 'num_leaves': 110, 'max_depth': 7, 'min_child_samples': 60, 'reg_alpha': 4, 'reg_lambda': 9, 'min_split_gain': 0.0, 'subsample': 0.9, 'subsample_freq': 1, 'colsample_bytree': 0.7000000000000001}. Best is trial 70 with value: 0.8942222171639829.\u001b[0m\n",
      "\u001b[32m[I 2022-06-29 19:12:02,390]\u001b[0m Trial 71 finished with value: 0.8938402377419595 and parameters: {'n_estimators': 10000, 'learning_rate': 0.24460394633616456, 'num_leaves': 120, 'max_depth': 7, 'min_child_samples': 50, 'reg_alpha': 3, 'reg_lambda': 8, 'min_split_gain': 0.0, 'subsample': 0.9, 'subsample_freq': 1, 'colsample_bytree': 0.7000000000000001}. Best is trial 70 with value: 0.8942222171639829.\u001b[0m\n",
      "\u001b[32m[I 2022-06-29 19:12:04,032]\u001b[0m Trial 72 finished with value: 0.8926632265933057 and parameters: {'n_estimators': 10000, 'learning_rate': 0.19019871846761952, 'num_leaves': 110, 'max_depth': 7, 'min_child_samples': 150, 'reg_alpha': 4, 'reg_lambda': 9, 'min_split_gain': 0.0, 'subsample': 0.9, 'subsample_freq': 1, 'colsample_bytree': 0.7000000000000001}. Best is trial 70 with value: 0.8942222171639829.\u001b[0m\n",
      "\u001b[32m[I 2022-06-29 19:12:05,722]\u001b[0m Trial 73 finished with value: 0.8941909590086745 and parameters: {'n_estimators': 10000, 'learning_rate': 0.15284551152717465, 'num_leaves': 105, 'max_depth': 7, 'min_child_samples': 140, 'reg_alpha': 3, 'reg_lambda': 9, 'min_split_gain': 0.0, 'subsample': 0.9, 'subsample_freq': 1, 'colsample_bytree': 0.7000000000000001}. Best is trial 70 with value: 0.8942222171639829.\u001b[0m\n",
      "\u001b[32m[I 2022-06-29 19:12:07,464]\u001b[0m Trial 74 finished with value: 0.8933779822953386 and parameters: {'n_estimators': 10000, 'learning_rate': 0.1342231122407727, 'num_leaves': 105, 'max_depth': 7, 'min_child_samples': 150, 'reg_alpha': 3, 'reg_lambda': 9, 'min_split_gain': 0.0, 'subsample': 0.9, 'subsample_freq': 1, 'colsample_bytree': 0.7000000000000001}. Best is trial 70 with value: 0.8942222171639829.\u001b[0m\n",
      "\u001b[32m[I 2022-06-29 19:12:09,150]\u001b[0m Trial 75 finished with value: 0.894297464357498 and parameters: {'n_estimators': 10000, 'learning_rate': 0.1607417882560753, 'num_leaves': 100, 'max_depth': 6, 'min_child_samples': 210, 'reg_alpha': 3, 'reg_lambda': 9, 'min_split_gain': 0.0, 'subsample': 0.9, 'subsample_freq': 1, 'colsample_bytree': 0.7000000000000001}. Best is trial 75 with value: 0.894297464357498.\u001b[0m\n",
      "\u001b[32m[I 2022-06-29 19:12:10,417]\u001b[0m Trial 76 finished with value: 0.8905395512271141 and parameters: {'n_estimators': 10000, 'learning_rate': 0.15085898135500295, 'num_leaves': 100, 'max_depth': 6, 'min_child_samples': 200, 'reg_alpha': 3, 'reg_lambda': 9, 'min_split_gain': 1.0, 'subsample': 0.9, 'subsample_freq': 1, 'colsample_bytree': 0.7000000000000001}. Best is trial 75 with value: 0.894297464357498.\u001b[0m\n",
      "\u001b[32m[I 2022-06-29 19:12:12,179]\u001b[0m Trial 77 finished with value: 0.8879058465190166 and parameters: {'n_estimators': 10000, 'learning_rate': 0.06162942466706184, 'num_leaves': 90, 'max_depth': 6, 'min_child_samples': 220, 'reg_alpha': 3, 'reg_lambda': 9, 'min_split_gain': 2.0, 'subsample': 0.9, 'subsample_freq': 1, 'colsample_bytree': 0.7000000000000001}. Best is trial 75 with value: 0.894297464357498.\u001b[0m\n",
      "\u001b[32m[I 2022-06-29 19:12:13,659]\u001b[0m Trial 78 finished with value: 0.8837981120180065 and parameters: {'n_estimators': 10000, 'learning_rate': 0.1573803175628323, 'num_leaves': 75, 'max_depth': 6, 'min_child_samples': 170, 'reg_alpha': 3, 'reg_lambda': 9, 'min_split_gain': 7.0, 'subsample': 0.9, 'subsample_freq': 1, 'colsample_bytree': 0.7000000000000001}. Best is trial 75 with value: 0.894297464357498.\u001b[0m\n",
      "\u001b[32m[I 2022-06-29 19:12:15,616]\u001b[0m Trial 79 finished with value: 0.8947225858567037 and parameters: {'n_estimators': 10000, 'learning_rate': 0.10288137603619629, 'num_leaves': 105, 'max_depth': 7, 'min_child_samples': 140, 'reg_alpha': 2, 'reg_lambda': 9, 'min_split_gain': 0.0, 'subsample': 0.9, 'subsample_freq': 1, 'colsample_bytree': 0.6000000000000001}. Best is trial 79 with value: 0.8947225858567037.\u001b[0m\n",
      "\u001b[32m[I 2022-06-29 19:12:16,904]\u001b[0m Trial 80 finished with value: 0.8873361593599516 and parameters: {'n_estimators': 10000, 'learning_rate': 0.0978503697456163, 'num_leaves': 95, 'max_depth': 7, 'min_child_samples': 290, 'reg_alpha': 2, 'reg_lambda': 9, 'min_split_gain': 1.5, 'subsample': 0.9, 'subsample_freq': 1, 'colsample_bytree': 0.6000000000000001}. Best is trial 79 with value: 0.8947225858567037.\u001b[0m\n",
      "\u001b[32m[I 2022-06-29 19:12:19,009]\u001b[0m Trial 81 finished with value: 0.89469638300001 and parameters: {'n_estimators': 10000, 'learning_rate': 0.12167564041361291, 'num_leaves': 105, 'max_depth': 7, 'min_child_samples': 140, 'reg_alpha': 3, 'reg_lambda': 9, 'min_split_gain': 0.0, 'subsample': 0.9, 'subsample_freq': 1, 'colsample_bytree': 0.6000000000000001}. Best is trial 79 with value: 0.8947225858567037.\u001b[0m\n",
      "\u001b[32m[I 2022-06-29 19:12:20,819]\u001b[0m Trial 82 finished with value: 0.8949252742168654 and parameters: {'n_estimators': 10000, 'learning_rate': 0.13546107315995753, 'num_leaves': 105, 'max_depth': 7, 'min_child_samples': 140, 'reg_alpha': 2, 'reg_lambda': 9, 'min_split_gain': 0.0, 'subsample': 0.9, 'subsample_freq': 1, 'colsample_bytree': 0.6000000000000001}. Best is trial 82 with value: 0.8949252742168654.\u001b[0m\n",
      "\u001b[32m[I 2022-06-29 19:12:22,505]\u001b[0m Trial 83 finished with value: 0.8922828087556713 and parameters: {'n_estimators': 10000, 'learning_rate': 0.12956334471796668, 'num_leaves': 90, 'max_depth': 7, 'min_child_samples': 180, 'reg_alpha': 2, 'reg_lambda': 9, 'min_split_gain': 1.0, 'subsample': 0.9, 'subsample_freq': 1, 'colsample_bytree': 0.6000000000000001}. Best is trial 82 with value: 0.8949252742168654.\u001b[0m\n",
      "\u001b[32m[I 2022-06-29 19:12:24,813]\u001b[0m Trial 84 finished with value: 0.8948517474129312 and parameters: {'n_estimators': 10000, 'learning_rate': 0.07104791159713107, 'num_leaves': 105, 'max_depth': 6, 'min_child_samples': 140, 'reg_alpha': 2, 'reg_lambda': 9, 'min_split_gain': 0.0, 'subsample': 0.9, 'subsample_freq': 1, 'colsample_bytree': 0.6000000000000001}. Best is trial 82 with value: 0.8949252742168654.\u001b[0m\n",
      "\u001b[32m[I 2022-06-29 19:12:26,247]\u001b[0m Trial 85 finished with value: 0.8923392640014567 and parameters: {'n_estimators': 10000, 'learning_rate': 0.07604877539733962, 'num_leaves': 105, 'max_depth': 6, 'min_child_samples': 150, 'reg_alpha': 2, 'reg_lambda': 9, 'min_split_gain': 1.0, 'subsample': 0.9, 'subsample_freq': 1, 'colsample_bytree': 0.6000000000000001}. Best is trial 82 with value: 0.8949252742168654.\u001b[0m\n",
      "\u001b[32m[I 2022-06-29 19:12:28,191]\u001b[0m Trial 86 finished with value: 0.894719489155458 and parameters: {'n_estimators': 10000, 'learning_rate': 0.12180502779392136, 'num_leaves': 95, 'max_depth': 6, 'min_child_samples': 210, 'reg_alpha': 2, 'reg_lambda': 9, 'min_split_gain': 0.0, 'subsample': 0.9, 'subsample_freq': 1, 'colsample_bytree': 0.6000000000000001}. Best is trial 82 with value: 0.8949252742168654.\u001b[0m\n",
      "\u001b[32m[I 2022-06-29 19:12:29,847]\u001b[0m Trial 87 finished with value: 0.8906084462129462 and parameters: {'n_estimators': 10000, 'learning_rate': 0.11395450883366046, 'num_leaves': 95, 'max_depth': 6, 'min_child_samples': 200, 'reg_alpha': 2, 'reg_lambda': 9, 'min_split_gain': 1.5, 'subsample': 0.9, 'subsample_freq': 1, 'colsample_bytree': 0.6000000000000001}. Best is trial 82 with value: 0.8949252742168654.\u001b[0m\n",
      "\u001b[32m[I 2022-06-29 19:12:31,173]\u001b[0m Trial 88 finished with value: 0.8911601883853059 and parameters: {'n_estimators': 10000, 'learning_rate': 0.16027324209990457, 'num_leaves': 85, 'max_depth': 5, 'min_child_samples': 230, 'reg_alpha': 2, 'reg_lambda': 9, 'min_split_gain': 0.5, 'subsample': 0.9, 'subsample_freq': 1, 'colsample_bytree': 0.6000000000000001}. Best is trial 82 with value: 0.8949252742168654.\u001b[0m\n",
      "\u001b[32m[I 2022-06-29 19:12:33,581]\u001b[0m Trial 89 finished with value: 0.8943245935778122 and parameters: {'n_estimators': 10000, 'learning_rate': 0.07425881760140164, 'num_leaves': 85, 'max_depth': 6, 'min_child_samples': 210, 'reg_alpha': 2, 'reg_lambda': 9, 'min_split_gain': 0.0, 'subsample': 0.9, 'subsample_freq': 1, 'colsample_bytree': 0.6000000000000001}. Best is trial 82 with value: 0.8949252742168654.\u001b[0m\n",
      "\u001b[32m[I 2022-06-29 19:12:35,990]\u001b[0m Trial 90 finished with value: 0.8859403675916717 and parameters: {'n_estimators': 10000, 'learning_rate': 0.07829309106206397, 'num_leaves': 80, 'max_depth': 6, 'min_child_samples': 550, 'reg_alpha': 2, 'reg_lambda': 9, 'min_split_gain': 0.5, 'subsample': 0.9, 'subsample_freq': 1, 'colsample_bytree': 0.6000000000000001}. Best is trial 82 with value: 0.8949252742168654.\u001b[0m\n",
      "\u001b[32m[I 2022-06-29 19:12:37,702]\u001b[0m Trial 91 finished with value: 0.882334378095047 and parameters: {'n_estimators': 10000, 'learning_rate': 0.11366896189900975, 'num_leaves': 100, 'max_depth': 5, 'min_child_samples': 320, 'reg_alpha': 2, 'reg_lambda': 9, 'min_split_gain': 6.0, 'subsample': 0.9, 'subsample_freq': 1, 'colsample_bytree': 0.6000000000000001}. Best is trial 82 with value: 0.8949252742168654.\u001b[0m\n",
      "\u001b[32m[I 2022-06-29 19:12:39,880]\u001b[0m Trial 92 finished with value: 0.8941934469566838 and parameters: {'n_estimators': 10000, 'learning_rate': 0.09541813474642644, 'num_leaves': 85, 'max_depth': 6, 'min_child_samples': 220, 'reg_alpha': 2, 'reg_lambda': 9, 'min_split_gain': 0.0, 'subsample': 0.9, 'subsample_freq': 1, 'colsample_bytree': 0.6000000000000001}. Best is trial 82 with value: 0.8949252742168654.\u001b[0m\n",
      "\u001b[32m[I 2022-06-29 19:12:41,537]\u001b[0m Trial 93 finished with value: 0.889532673374245 and parameters: {'n_estimators': 10000, 'learning_rate': 0.0954758874821295, 'num_leaves': 60, 'max_depth': 6, 'min_child_samples': 250, 'reg_alpha': 2, 'reg_lambda': 9, 'min_split_gain': 1.0, 'subsample': 0.9, 'subsample_freq': 1, 'colsample_bytree': 0.6000000000000001}. Best is trial 82 with value: 0.8949252742168654.\u001b[0m\n",
      "\u001b[32m[I 2022-06-29 19:12:44,936]\u001b[0m Trial 94 finished with value: 0.8915752522223463 and parameters: {'n_estimators': 10000, 'learning_rate': 0.046177670454527364, 'num_leaves': 85, 'max_depth': 6, 'min_child_samples': 370, 'reg_alpha': 2, 'reg_lambda': 9, 'min_split_gain': 0.0, 'subsample': 0.9, 'subsample_freq': 1, 'colsample_bytree': 0.6000000000000001}. Best is trial 82 with value: 0.8949252742168654.\u001b[0m\n",
      "\u001b[32m[I 2022-06-29 19:12:46,752]\u001b[0m Trial 95 finished with value: 0.8949542032293565 and parameters: {'n_estimators': 10000, 'learning_rate': 0.13981632269094546, 'num_leaves': 75, 'max_depth': 6, 'min_child_samples': 210, 'reg_alpha': 2, 'reg_lambda': 9, 'min_split_gain': 0.0, 'subsample': 0.9, 'subsample_freq': 1, 'colsample_bytree': 0.6000000000000001}. Best is trial 95 with value: 0.8949542032293565.\u001b[0m\n",
      "\u001b[32m[I 2022-06-29 19:12:48,394]\u001b[0m Trial 96 finished with value: 0.8899412261984101 and parameters: {'n_estimators': 10000, 'learning_rate': 0.08828725456281439, 'num_leaves': 70, 'max_depth': 5, 'min_child_samples': 280, 'reg_alpha': 1, 'reg_lambda': 9, 'min_split_gain': 0.5, 'subsample': 0.9, 'subsample_freq': 1, 'colsample_bytree': 0.6000000000000001}. Best is trial 95 with value: 0.8949542032293565.\u001b[0m\n",
      "\u001b[32m[I 2022-06-29 19:12:49,774]\u001b[0m Trial 97 finished with value: 0.8905375661622132 and parameters: {'n_estimators': 10000, 'learning_rate': 0.13909374810876354, 'num_leaves': 75, 'max_depth': 6, 'min_child_samples': 210, 'reg_alpha': 2, 'reg_lambda': 9, 'min_split_gain': 1.0, 'subsample': 0.9, 'subsample_freq': 1, 'colsample_bytree': 0.6000000000000001}. Best is trial 95 with value: 0.8949542032293565.\u001b[0m\n",
      "\u001b[32m[I 2022-06-29 19:12:50,999]\u001b[0m Trial 98 finished with value: 0.8903653154638673 and parameters: {'n_estimators': 10000, 'learning_rate': 0.1222403794062517, 'num_leaves': 60, 'max_depth': 5, 'min_child_samples': 180, 'reg_alpha': 2, 'reg_lambda': 9, 'min_split_gain': 1.5, 'subsample': 0.9, 'subsample_freq': 1, 'colsample_bytree': 0.6000000000000001}. Best is trial 95 with value: 0.8949542032293565.\u001b[0m\n",
      "\u001b[32m[I 2022-06-29 19:12:52,911]\u001b[0m Trial 99 finished with value: 0.8881610199951617 and parameters: {'n_estimators': 10000, 'learning_rate': 0.10371898265050955, 'num_leaves': 95, 'max_depth': 6, 'min_child_samples': 230, 'reg_alpha': 2, 'reg_lambda': 9, 'min_split_gain': 2.0, 'subsample': 0.9, 'subsample_freq': 1, 'colsample_bytree': 0.6000000000000001}. Best is trial 95 with value: 0.8949542032293565.\u001b[0m\n",
      "\u001b[32m[I 2022-06-29 19:12:54,266]\u001b[0m Trial 100 finished with value: 0.8787138049882828 and parameters: {'n_estimators': 10000, 'learning_rate': 0.16538868955037983, 'num_leaves': 90, 'max_depth': 6, 'min_child_samples': 250, 'reg_alpha': 2, 'reg_lambda': 9, 'min_split_gain': 11.0, 'subsample': 0.9, 'subsample_freq': 1, 'colsample_bytree': 0.6000000000000001}. Best is trial 95 with value: 0.8949542032293565.\u001b[0m\n",
      "\u001b[32m[I 2022-06-29 19:12:55,884]\u001b[0m Trial 101 finished with value: 0.8906330345501869 and parameters: {'n_estimators': 10000, 'learning_rate': 0.14238441217707953, 'num_leaves': 100, 'max_depth': 6, 'min_child_samples': 460, 'reg_alpha': 1, 'reg_lambda': 9, 'min_split_gain': 0.0, 'subsample': 0.9, 'subsample_freq': 1, 'colsample_bytree': 0.6000000000000001}. Best is trial 95 with value: 0.8949542032293565.\u001b[0m\n",
      "\u001b[32m[I 2022-06-29 19:12:58,262]\u001b[0m Trial 102 finished with value: 0.895654719399166 and parameters: {'n_estimators': 10000, 'learning_rate': 0.06988773314307496, 'num_leaves': 220, 'max_depth': 7, 'min_child_samples': 130, 'reg_alpha': 1, 'reg_lambda': 9, 'min_split_gain': 0.0, 'subsample': 0.9, 'subsample_freq': 1, 'colsample_bytree': 0.6000000000000001}. Best is trial 102 with value: 0.895654719399166.\u001b[0m\n",
      "\u001b[32m[I 2022-06-29 19:13:00,114]\u001b[0m Trial 103 finished with value: 0.8935275503187485 and parameters: {'n_estimators': 10000, 'learning_rate': 0.064226424203641, 'num_leaves': 80, 'max_depth': 6, 'min_child_samples': 170, 'reg_alpha': 1, 'reg_lambda': 9, 'min_split_gain': 0.5, 'subsample': 0.9, 'subsample_freq': 1, 'colsample_bytree': 0.6000000000000001}. Best is trial 102 with value: 0.895654719399166.\u001b[0m\n",
      "\u001b[32m[I 2022-06-29 19:13:04,797]\u001b[0m Trial 104 finished with value: 0.8956954793984669 and parameters: {'n_estimators': 10000, 'learning_rate': 0.02469553171520475, 'num_leaves': 85, 'max_depth': 6, 'min_child_samples': 190, 'reg_alpha': 1, 'reg_lambda': 9, 'min_split_gain': 0.0, 'subsample': 0.9, 'subsample_freq': 1, 'colsample_bytree': 0.6000000000000001}. Best is trial 104 with value: 0.8956954793984669.\u001b[0m\n",
      "\u001b[32m[I 2022-06-29 19:13:07,515]\u001b[0m Trial 105 finished with value: 0.8930540991060856 and parameters: {'n_estimators': 10000, 'learning_rate': 0.029308460610382305, 'num_leaves': 75, 'max_depth': 7, 'min_child_samples': 120, 'reg_alpha': 1, 'reg_lambda': 9, 'min_split_gain': 1.0, 'subsample': 0.9, 'subsample_freq': 1, 'colsample_bytree': 0.6000000000000001}. Best is trial 104 with value: 0.8956954793984669.\u001b[0m\n",
      "\u001b[32m[I 2022-06-29 19:13:09,636]\u001b[0m Trial 106 finished with value: 0.8932464121936978 and parameters: {'n_estimators': 10000, 'learning_rate': 0.0608841536699338, 'num_leaves': 225, 'max_depth': 7, 'min_child_samples': 200, 'reg_alpha': 1, 'reg_lambda': 9, 'min_split_gain': 0.5, 'subsample': 0.9, 'subsample_freq': 1, 'colsample_bytree': 0.5}. Best is trial 104 with value: 0.8956954793984669.\u001b[0m\n",
      "\u001b[32m[I 2022-06-29 19:13:13,293]\u001b[0m Trial 107 finished with value: 0.8845132912005512 and parameters: {'n_estimators': 10000, 'learning_rate': 0.01976479395096875, 'num_leaves': 210, 'max_depth': 6, 'min_child_samples': 160, 'reg_alpha': 1, 'reg_lambda': 9, 'min_split_gain': 8.0, 'subsample': 0.9, 'subsample_freq': 1, 'colsample_bytree': 0.6000000000000001}. Best is trial 104 with value: 0.8956954793984669.\u001b[0m\n",
      "\u001b[32m[I 2022-06-29 19:13:15,409]\u001b[0m Trial 108 finished with value: 0.895340549794162 and parameters: {'n_estimators': 10000, 'learning_rate': 0.0811297051782589, 'num_leaves': 65, 'max_depth': 6, 'min_child_samples': 110, 'reg_alpha': 1, 'reg_lambda': 9, 'min_split_gain': 0.0, 'subsample': 0.9, 'subsample_freq': 1, 'colsample_bytree': 0.6000000000000001}. Best is trial 104 with value: 0.8956954793984669.\u001b[0m\n",
      "\u001b[32m[I 2022-06-29 19:13:17,304]\u001b[0m Trial 109 finished with value: 0.8930981146118245 and parameters: {'n_estimators': 10000, 'learning_rate': 0.07662514766155872, 'num_leaves': 60, 'max_depth': 5, 'min_child_samples': 190, 'reg_alpha': 1, 'reg_lambda': 9, 'min_split_gain': 0.5, 'subsample': 0.9, 'subsample_freq': 1, 'colsample_bytree': 0.5}. Best is trial 104 with value: 0.8956954793984669.\u001b[0m\n",
      "\u001b[32m[I 2022-06-29 19:13:20,461]\u001b[0m Trial 110 finished with value: 0.8956953470608069 and parameters: {'n_estimators': 10000, 'learning_rate': 0.05165880572778485, 'num_leaves': 70, 'max_depth': 6, 'min_child_samples': 130, 'reg_alpha': 1, 'reg_lambda': 9, 'min_split_gain': 0.0, 'subsample': 0.9, 'subsample_freq': 1, 'colsample_bytree': 0.6000000000000001}. Best is trial 104 with value: 0.8956954793984669.\u001b[0m\n",
      "\u001b[32m[I 2022-06-29 19:13:23,113]\u001b[0m Trial 111 finished with value: 0.8955066600250806 and parameters: {'n_estimators': 10000, 'learning_rate': 0.051754657713547814, 'num_leaves': 65, 'max_depth': 6, 'min_child_samples': 130, 'reg_alpha': 1, 'reg_lambda': 9, 'min_split_gain': 0.0, 'subsample': 0.9, 'subsample_freq': 1, 'colsample_bytree': 0.6000000000000001}. Best is trial 104 with value: 0.8956954793984669.\u001b[0m\n",
      "\u001b[32m[I 2022-06-29 19:13:24,835]\u001b[0m Trial 112 finished with value: 0.8929637654193225 and parameters: {'n_estimators': 10000, 'learning_rate': 0.0531060823092917, 'num_leaves': 50, 'max_depth': 6, 'min_child_samples': 100, 'reg_alpha': 1, 'reg_lambda': 9, 'min_split_gain': 1.0, 'subsample': 0.9, 'subsample_freq': 1, 'colsample_bytree': 0.6000000000000001}. Best is trial 104 with value: 0.8956954793984669.\u001b[0m\n",
      "\u001b[32m[I 2022-06-29 19:13:34,348]\u001b[0m Trial 113 finished with value: 0.892299377430712 and parameters: {'n_estimators': 10000, 'learning_rate': 0.011479391636985345, 'num_leaves': 65, 'max_depth': 6, 'min_child_samples': 120, 'reg_alpha': 1, 'reg_lambda': 9, 'min_split_gain': 0.0, 'subsample': 0.4, 'subsample_freq': 1, 'colsample_bytree': 0.6000000000000001}. Best is trial 104 with value: 0.8956954793984669.\u001b[0m\n",
      "\u001b[32m[I 2022-06-29 19:13:36,726]\u001b[0m Trial 114 finished with value: 0.8943424856294535 and parameters: {'n_estimators': 10000, 'learning_rate': 0.039357952837154105, 'num_leaves': 65, 'max_depth': 6, 'min_child_samples': 140, 'reg_alpha': 0, 'reg_lambda': 9, 'min_split_gain': 0.5, 'subsample': 0.9, 'subsample_freq': 1, 'colsample_bytree': 0.6000000000000001}. Best is trial 104 with value: 0.8956954793984669.\u001b[0m\n",
      "\u001b[32m[I 2022-06-29 19:13:39,038]\u001b[0m Trial 115 finished with value: 0.8940601299979302 and parameters: {'n_estimators': 10000, 'learning_rate': 0.03834541889505167, 'num_leaves': 65, 'max_depth': 6, 'min_child_samples': 140, 'reg_alpha': 0, 'reg_lambda': 9, 'min_split_gain': 0.5, 'subsample': 0.9, 'subsample_freq': 1, 'colsample_bytree': 0.6000000000000001}. Best is trial 104 with value: 0.8956954793984669.\u001b[0m\n",
      "\u001b[32m[I 2022-06-29 19:13:42,311]\u001b[0m Trial 116 finished with value: 0.8930011111069939 and parameters: {'n_estimators': 10000, 'learning_rate': 0.022681148859311197, 'num_leaves': 65, 'max_depth': 6, 'min_child_samples': 80, 'reg_alpha': 1, 'reg_lambda': 9, 'min_split_gain': 1.5, 'subsample': 0.9, 'subsample_freq': 1, 'colsample_bytree': 0.6000000000000001}. Best is trial 104 with value: 0.8956954793984669.\u001b[0m\n",
      "\u001b[32m[I 2022-06-29 19:13:43,819]\u001b[0m Trial 117 finished with value: 0.8940637295822841 and parameters: {'n_estimators': 10000, 'learning_rate': 0.08809216831061573, 'num_leaves': 50, 'max_depth': 5, 'min_child_samples': 110, 'reg_alpha': 1, 'reg_lambda': 9, 'min_split_gain': 0.5, 'subsample': 0.9, 'subsample_freq': 1, 'colsample_bytree': 0.6000000000000001}. Best is trial 104 with value: 0.8956954793984669.\u001b[0m\n",
      "\u001b[32m[I 2022-06-29 19:13:45,611]\u001b[0m Trial 118 finished with value: 0.8933285409455367 and parameters: {'n_estimators': 10000, 'learning_rate': 0.0492251941022607, 'num_leaves': 70, 'max_depth': 7, 'min_child_samples': 130, 'reg_alpha': 0, 'reg_lambda': 9, 'min_split_gain': 1.0, 'subsample': 0.9, 'subsample_freq': 1, 'colsample_bytree': 0.6000000000000001}. Best is trial 104 with value: 0.8956954793984669.\u001b[0m\n",
      "\u001b[32m[I 2022-06-29 19:13:49,505]\u001b[0m Trial 119 finished with value: 0.8856252186879833 and parameters: {'n_estimators': 10000, 'learning_rate': 0.03598860732559196, 'num_leaves': 55, 'max_depth': 6, 'min_child_samples': 640, 'reg_alpha': 1, 'reg_lambda': 9, 'min_split_gain': 0.5, 'subsample': 0.9, 'subsample_freq': 1, 'colsample_bytree': 0.6000000000000001}. Best is trial 104 with value: 0.8956954793984669.\u001b[0m\n",
      "\u001b[32m[I 2022-06-29 19:13:53,285]\u001b[0m Trial 120 finished with value: 0.8882868995774194 and parameters: {'n_estimators': 10000, 'learning_rate': 0.0682271851183844, 'num_leaves': 195, 'max_depth': 7, 'min_child_samples': 730, 'reg_alpha': 0, 'reg_lambda': 9, 'min_split_gain': 0.0, 'subsample': 0.9, 'subsample_freq': 1, 'colsample_bytree': 0.6000000000000001}. Best is trial 104 with value: 0.8956954793984669.\u001b[0m\n",
      "\u001b[32m[I 2022-06-29 19:13:55,276]\u001b[0m Trial 121 finished with value: 0.8956899741518082 and parameters: {'n_estimators': 10000, 'learning_rate': 0.08338120160667788, 'num_leaves': 75, 'max_depth': 6, 'min_child_samples': 160, 'reg_alpha': 0, 'reg_lambda': 9, 'min_split_gain': 0.0, 'subsample': 0.9, 'subsample_freq': 1, 'colsample_bytree': 0.6000000000000001}. Best is trial 104 with value: 0.8956954793984669.\u001b[0m\n",
      "\u001b[32m[I 2022-06-29 19:13:57,058]\u001b[0m Trial 122 finished with value: 0.8962144282986618 and parameters: {'n_estimators': 10000, 'learning_rate': 0.12028846839368543, 'num_leaves': 80, 'max_depth': 6, 'min_child_samples': 170, 'reg_alpha': 0, 'reg_lambda': 9, 'min_split_gain': 0.0, 'subsample': 0.9, 'subsample_freq': 1, 'colsample_bytree': 0.6000000000000001}. Best is trial 122 with value: 0.8962144282986618.\u001b[0m\n",
      "\u001b[32m[I 2022-06-29 19:13:58,747]\u001b[0m Trial 123 finished with value: 0.8958521671879889 and parameters: {'n_estimators': 10000, 'learning_rate': 0.12412818101850523, 'num_leaves': 75, 'max_depth': 6, 'min_child_samples': 170, 'reg_alpha': 0, 'reg_lambda': 9, 'min_split_gain': 0.0, 'subsample': 0.9, 'subsample_freq': 1, 'colsample_bytree': 0.6000000000000001}. Best is trial 122 with value: 0.8962144282986618.\u001b[0m\n",
      "\u001b[32m[I 2022-06-29 19:14:00,588]\u001b[0m Trial 124 finished with value: 0.8961006973135984 and parameters: {'n_estimators': 10000, 'learning_rate': 0.10758747144230628, 'num_leaves': 80, 'max_depth': 6, 'min_child_samples': 170, 'reg_alpha': 0, 'reg_lambda': 9, 'min_split_gain': 0.0, 'subsample': 0.9, 'subsample_freq': 1, 'colsample_bytree': 0.6000000000000001}. Best is trial 122 with value: 0.8962144282986618.\u001b[0m\n",
      "\u001b[32m[I 2022-06-29 19:14:01,939]\u001b[0m Trial 125 finished with value: 0.8929541312376694 and parameters: {'n_estimators': 10000, 'learning_rate': 0.08573133798407184, 'num_leaves': 75, 'max_depth': 6, 'min_child_samples': 160, 'reg_alpha': 0, 'reg_lambda': 9, 'min_split_gain': 1.0, 'subsample': 0.9, 'subsample_freq': 1, 'colsample_bytree': 0.6000000000000001}. Best is trial 122 with value: 0.8962144282986618.\u001b[0m\n",
      "\u001b[32m[I 2022-06-29 19:14:04,630]\u001b[0m Trial 126 finished with value: 0.896314634374866 and parameters: {'n_estimators': 10000, 'learning_rate': 0.0542643883256055, 'num_leaves': 80, 'max_depth': 6, 'min_child_samples': 180, 'reg_alpha': 0, 'reg_lambda': 9, 'min_split_gain': 0.0, 'subsample': 0.9, 'subsample_freq': 1, 'colsample_bytree': 0.6000000000000001}. Best is trial 126 with value: 0.896314634374866.\u001b[0m\n",
      "\u001b[32m[I 2022-06-29 19:14:06,713]\u001b[0m Trial 127 finished with value: 0.8938873764164762 and parameters: {'n_estimators': 10000, 'learning_rate': 0.0535870983235112, 'num_leaves': 80, 'max_depth': 6, 'min_child_samples': 180, 'reg_alpha': 0, 'reg_lambda': 9, 'min_split_gain': 0.5, 'subsample': 0.9, 'subsample_freq': 1, 'colsample_bytree': 0.6000000000000001}. Best is trial 126 with value: 0.896314634374866.\u001b[0m\n",
      "\u001b[32m[I 2022-06-29 19:14:08,580]\u001b[0m Trial 128 finished with value: 0.8960799203009676 and parameters: {'n_estimators': 10000, 'learning_rate': 0.10902175590589261, 'num_leaves': 70, 'max_depth': 6, 'min_child_samples': 100, 'reg_alpha': 0, 'reg_lambda': 9, 'min_split_gain': 0.0, 'subsample': 0.9, 'subsample_freq': 1, 'colsample_bytree': 0.5}. Best is trial 126 with value: 0.896314634374866.\u001b[0m\n",
      "\u001b[32m[I 2022-06-29 19:14:09,714]\u001b[0m Trial 129 finished with value: 0.8932953771279234 and parameters: {'n_estimators': 10000, 'learning_rate': 0.11236710143329846, 'num_leaves': 70, 'max_depth': 5, 'min_child_samples': 100, 'reg_alpha': 0, 'reg_lambda': 9, 'min_split_gain': 1.0, 'subsample': 0.9, 'subsample_freq': 1, 'colsample_bytree': 0.5}. Best is trial 126 with value: 0.896314634374866.\u001b[0m\n",
      "\u001b[32m[I 2022-06-29 19:14:11,207]\u001b[0m Trial 130 finished with value: 0.8917062665058147 and parameters: {'n_estimators': 10000, 'learning_rate': 0.0835352846939154, 'num_leaves': 80, 'max_depth': 4, 'min_child_samples': 170, 'reg_alpha': 0, 'reg_lambda': 9, 'min_split_gain': 1.5, 'subsample': 0.9, 'subsample_freq': 1, 'colsample_bytree': 0.5}. Best is trial 126 with value: 0.896314634374866.\u001b[0m\n",
      "\u001b[32m[I 2022-06-29 19:14:13,715]\u001b[0m Trial 131 finished with value: 0.8929324543289502 and parameters: {'n_estimators': 10000, 'learning_rate': 0.06951627728941376, 'num_leaves': 75, 'max_depth': 6, 'min_child_samples': 160, 'reg_alpha': 0, 'reg_lambda': 9, 'min_split_gain': 0.0, 'subsample': 0.5, 'subsample_freq': 1, 'colsample_bytree': 0.6000000000000001}. Best is trial 126 with value: 0.896314634374866.\u001b[0m\n",
      "\u001b[32m[I 2022-06-29 19:14:16,138]\u001b[0m Trial 132 finished with value: 0.8963350673095807 and parameters: {'n_estimators': 10000, 'learning_rate': 0.056707993417928905, 'num_leaves': 55, 'max_depth': 6, 'min_child_samples': 120, 'reg_alpha': 0, 'reg_lambda': 9, 'min_split_gain': 0.0, 'subsample': 0.9, 'subsample_freq': 1, 'colsample_bytree': 0.5}. Best is trial 132 with value: 0.8963350673095807.\u001b[0m\n",
      "\u001b[32m[I 2022-06-29 19:14:18,041]\u001b[0m Trial 133 finished with value: 0.8945567403011052 and parameters: {'n_estimators': 10000, 'learning_rate': 0.05412852199645894, 'num_leaves': 55, 'max_depth': 6, 'min_child_samples': 90, 'reg_alpha': 0, 'reg_lambda': 9, 'min_split_gain': 0.5, 'subsample': 0.9, 'subsample_freq': 1, 'colsample_bytree': 0.5}. Best is trial 132 with value: 0.8963350673095807.\u001b[0m\n",
      "\u001b[32m[I 2022-06-29 19:14:19,829]\u001b[0m Trial 134 finished with value: 0.8967679437956664 and parameters: {'n_estimators': 10000, 'learning_rate': 0.10982748325689601, 'num_leaves': 60, 'max_depth': 6, 'min_child_samples': 70, 'reg_alpha': 0, 'reg_lambda': 9, 'min_split_gain': 0.0, 'subsample': 0.9, 'subsample_freq': 1, 'colsample_bytree': 0.5}. Best is trial 134 with value: 0.8967679437956664.\u001b[0m\n",
      "\u001b[32m[I 2022-06-29 19:14:21,236]\u001b[0m Trial 135 finished with value: 0.8948338288937577 and parameters: {'n_estimators': 10000, 'learning_rate': 0.10435900200216154, 'num_leaves': 60, 'max_depth': 6, 'min_child_samples': 70, 'reg_alpha': 0, 'reg_lambda': 9, 'min_split_gain': 0.5, 'subsample': 0.9, 'subsample_freq': 1, 'colsample_bytree': 0.5}. Best is trial 134 with value: 0.8967679437956664.\u001b[0m\n",
      "\u001b[32m[I 2022-06-29 19:14:23,781]\u001b[0m Trial 136 finished with value: 0.8795724911294066 and parameters: {'n_estimators': 10000, 'learning_rate': 0.027194351107189166, 'num_leaves': 70, 'max_depth': 6, 'min_child_samples': 120, 'reg_alpha': 0, 'reg_lambda': 9, 'min_split_gain': 13.5, 'subsample': 0.9, 'subsample_freq': 1, 'colsample_bytree': 0.5}. Best is trial 134 with value: 0.8967679437956664.\u001b[0m\n",
      "\u001b[32m[I 2022-06-29 19:14:25,760]\u001b[0m Trial 137 finished with value: 0.8963291915174737 and parameters: {'n_estimators': 10000, 'learning_rate': 0.09592825133120342, 'num_leaves': 55, 'max_depth': 6, 'min_child_samples': 80, 'reg_alpha': 0, 'reg_lambda': 9, 'min_split_gain': 0.0, 'subsample': 0.9, 'subsample_freq': 1, 'colsample_bytree': 0.5}. Best is trial 134 with value: 0.8967679437956664.\u001b[0m\n",
      "\u001b[32m[I 2022-06-29 19:14:27,202]\u001b[0m Trial 138 finished with value: 0.8943581279408738 and parameters: {'n_estimators': 10000, 'learning_rate': 0.09624832394228885, 'num_leaves': 55, 'max_depth': 6, 'min_child_samples': 80, 'reg_alpha': 0, 'reg_lambda': 9, 'min_split_gain': 0.5, 'subsample': 0.9, 'subsample_freq': 1, 'colsample_bytree': 0.5}. Best is trial 134 with value: 0.8967679437956664.\u001b[0m\n",
      "\u001b[32m[I 2022-06-29 19:14:29,693]\u001b[0m Trial 139 finished with value: 0.8962323203503031 and parameters: {'n_estimators': 10000, 'learning_rate': 0.06070567176560568, 'num_leaves': 50, 'max_depth': 6, 'min_child_samples': 100, 'reg_alpha': 0, 'reg_lambda': 9, 'min_split_gain': 0.0, 'subsample': 0.9, 'subsample_freq': 1, 'colsample_bytree': 0.5}. Best is trial 134 with value: 0.8967679437956664.\u001b[0m\n",
      "\u001b[32m[I 2022-06-29 19:14:31,796]\u001b[0m Trial 140 finished with value: 0.8936201866807968 and parameters: {'n_estimators': 10000, 'learning_rate': 0.04334651951339405, 'num_leaves': 50, 'max_depth': 5, 'min_child_samples': 100, 'reg_alpha': 0, 'reg_lambda': 9, 'min_split_gain': 1.0, 'subsample': 0.9, 'subsample_freq': 1, 'colsample_bytree': 0.5}. Best is trial 134 with value: 0.8967679437956664.\u001b[0m\n",
      "\u001b[32m[I 2022-06-29 19:14:34,292]\u001b[0m Trial 141 finished with value: 0.8965554889161917 and parameters: {'n_estimators': 10000, 'learning_rate': 0.05827195474329799, 'num_leaves': 65, 'max_depth': 6, 'min_child_samples': 110, 'reg_alpha': 0, 'reg_lambda': 9, 'min_split_gain': 0.0, 'subsample': 0.9, 'subsample_freq': 1, 'colsample_bytree': 0.5}. Best is trial 134 with value: 0.8967679437956664.\u001b[0m\n",
      "\u001b[32m[I 2022-06-29 19:14:36,400]\u001b[0m Trial 142 finished with value: 0.8965151259298705 and parameters: {'n_estimators': 10000, 'learning_rate': 0.061516924098348844, 'num_leaves': 55, 'max_depth': 6, 'min_child_samples': 80, 'reg_alpha': 0, 'reg_lambda': 9, 'min_split_gain': 0.0, 'subsample': 0.9, 'subsample_freq': 1, 'colsample_bytree': 0.5}. Best is trial 134 with value: 0.8967679437956664.\u001b[0m\n",
      "\u001b[32m[I 2022-06-29 19:14:38,282]\u001b[0m Trial 143 finished with value: 0.8947513295964706 and parameters: {'n_estimators': 10000, 'learning_rate': 0.0579925585637505, 'num_leaves': 55, 'max_depth': 6, 'min_child_samples': 80, 'reg_alpha': 0, 'reg_lambda': 9, 'min_split_gain': 0.5, 'subsample': 0.9, 'subsample_freq': 1, 'colsample_bytree': 0.5}. Best is trial 134 with value: 0.8967679437956664.\u001b[0m\n",
      "\u001b[32m[I 2022-06-29 19:14:40,630]\u001b[0m Trial 144 finished with value: 0.8968558160019523 and parameters: {'n_estimators': 10000, 'learning_rate': 0.0660742790071791, 'num_leaves': 60, 'max_depth': 6, 'min_child_samples': 70, 'reg_alpha': 0, 'reg_lambda': 9, 'min_split_gain': 0.0, 'subsample': 0.9, 'subsample_freq': 1, 'colsample_bytree': 0.5}. Best is trial 144 with value: 0.8968558160019523.\u001b[0m\n",
      "\u001b[32m[I 2022-06-29 19:14:42,025]\u001b[0m Trial 145 finished with value: 0.8940494635825288 and parameters: {'n_estimators': 10000, 'learning_rate': 0.0911786365608972, 'num_leaves': 60, 'max_depth': 6, 'min_child_samples': 70, 'reg_alpha': 0, 'reg_lambda': 9, 'min_split_gain': 1.0, 'subsample': 0.9, 'subsample_freq': 1, 'colsample_bytree': 0.5}. Best is trial 144 with value: 0.8968558160019523.\u001b[0m\n",
      "\u001b[32m[I 2022-06-29 19:14:48,146]\u001b[0m Trial 146 finished with value: 0.8948432513351547 and parameters: {'n_estimators': 10000, 'learning_rate': 0.010000739333085795, 'num_leaves': 50, 'max_depth': 6, 'min_child_samples': 60, 'reg_alpha': 0, 'reg_lambda': 9, 'min_split_gain': 0.5, 'subsample': 0.9, 'subsample_freq': 1, 'colsample_bytree': 0.5}. Best is trial 144 with value: 0.8968558160019523.\u001b[0m\n",
      "\u001b[32m[I 2022-06-29 19:14:51,750]\u001b[0m Trial 147 finished with value: 0.8968301689634308 and parameters: {'n_estimators': 10000, 'learning_rate': 0.030575749804628932, 'num_leaves': 60, 'max_depth': 6, 'min_child_samples': 50, 'reg_alpha': 0, 'reg_lambda': 9, 'min_split_gain': 0.0, 'subsample': 0.9, 'subsample_freq': 1, 'colsample_bytree': 0.5}. Best is trial 144 with value: 0.8968558160019523.\u001b[0m\n",
      "\u001b[32m[I 2022-06-29 19:14:55,722]\u001b[0m Trial 148 finished with value: 0.8969993229605311 and parameters: {'n_estimators': 10000, 'learning_rate': 0.032834420566704714, 'num_leaves': 55, 'max_depth': 6, 'min_child_samples': 50, 'reg_alpha': 0, 'reg_lambda': 9, 'min_split_gain': 0.0, 'subsample': 0.9, 'subsample_freq': 1, 'colsample_bytree': 0.5}. Best is trial 148 with value: 0.8969993229605311.\u001b[0m\n",
      "\u001b[32m[I 2022-06-29 19:14:58,525]\u001b[0m Trial 149 finished with value: 0.894886208139613 and parameters: {'n_estimators': 10000, 'learning_rate': 0.030591231861763154, 'num_leaves': 55, 'max_depth': 5, 'min_child_samples': 60, 'reg_alpha': 0, 'reg_lambda': 9, 'min_split_gain': 0.5, 'subsample': 0.9, 'subsample_freq': 1, 'colsample_bytree': 0.5}. Best is trial 148 with value: 0.8969993229605311.\u001b[0m\n",
      "\u001b[32m[I 2022-06-29 19:15:04,044]\u001b[0m Trial 150 finished with value: 0.897210322125745 and parameters: {'n_estimators': 10000, 'learning_rate': 0.019562382426637867, 'num_leaves': 60, 'max_depth': 6, 'min_child_samples': 50, 'reg_alpha': 0, 'reg_lambda': 9, 'min_split_gain': 0.0, 'subsample': 0.9, 'subsample_freq': 1, 'colsample_bytree': 0.5}. Best is trial 150 with value: 0.897210322125745.\u001b[0m\n",
      "\u001b[32m[I 2022-06-29 19:15:08,970]\u001b[0m Trial 151 finished with value: 0.8964213779314777 and parameters: {'n_estimators': 10000, 'learning_rate': 0.019829759322491765, 'num_leaves': 60, 'max_depth': 6, 'min_child_samples': 90, 'reg_alpha': 0, 'reg_lambda': 9, 'min_split_gain': 0.0, 'subsample': 0.9, 'subsample_freq': 1, 'colsample_bytree': 0.5}. Best is trial 150 with value: 0.897210322125745.\u001b[0m\n",
      "\u001b[32m[I 2022-06-29 19:15:12,410]\u001b[0m Trial 152 finished with value: 0.896166998481293 and parameters: {'n_estimators': 10000, 'learning_rate': 0.037652921502509124, 'num_leaves': 60, 'max_depth': 6, 'min_child_samples': 90, 'reg_alpha': 0, 'reg_lambda': 9, 'min_split_gain': 0.0, 'subsample': 0.9, 'subsample_freq': 1, 'colsample_bytree': 0.5}. Best is trial 150 with value: 0.897210322125745.\u001b[0m\n",
      "\u001b[32m[I 2022-06-29 19:15:14,448]\u001b[0m Trial 153 finished with value: 0.881549933381222 and parameters: {'n_estimators': 10000, 'learning_rate': 0.041325200288032424, 'num_leaves': 60, 'max_depth': 6, 'min_child_samples': 50, 'reg_alpha': 0, 'reg_lambda': 9, 'min_split_gain': 12.0, 'subsample': 0.9, 'subsample_freq': 1, 'colsample_bytree': 0.5}. Best is trial 150 with value: 0.897210322125745.\u001b[0m\n",
      "\u001b[32m[I 2022-06-29 19:15:18,510]\u001b[0m Trial 154 finished with value: 0.8945620338075081 and parameters: {'n_estimators': 10000, 'learning_rate': 0.020268842418668023, 'num_leaves': 50, 'max_depth': 6, 'min_child_samples': 90, 'reg_alpha': 0, 'reg_lambda': 9, 'min_split_gain': 0.5, 'subsample': 0.9, 'subsample_freq': 1, 'colsample_bytree': 0.5}. Best is trial 150 with value: 0.897210322125745.\u001b[0m\n",
      "\u001b[32m[I 2022-06-29 19:15:22,264]\u001b[0m Trial 155 finished with value: 0.8968648414303689 and parameters: {'n_estimators': 10000, 'learning_rate': 0.03111475266014155, 'num_leaves': 55, 'max_depth': 6, 'min_child_samples': 50, 'reg_alpha': 0, 'reg_lambda': 9, 'min_split_gain': 0.0, 'subsample': 0.9, 'subsample_freq': 1, 'colsample_bytree': 0.5}. Best is trial 150 with value: 0.897210322125745.\u001b[0m\n",
      "\u001b[32m[I 2022-06-29 19:15:25,029]\u001b[0m Trial 156 finished with value: 0.8853781178091022 and parameters: {'n_estimators': 10000, 'learning_rate': 0.030319719138765605, 'num_leaves': 55, 'max_depth': 6, 'min_child_samples': 50, 'reg_alpha': 0, 'reg_lambda': 9, 'min_split_gain': 8.5, 'subsample': 0.9, 'subsample_freq': 1, 'colsample_bytree': 0.5}. Best is trial 150 with value: 0.897210322125745.\u001b[0m\n",
      "\u001b[32m[I 2022-06-29 19:15:29,134]\u001b[0m Trial 157 finished with value: 0.8942063895798384 and parameters: {'n_estimators': 10000, 'learning_rate': 0.01639844921431316, 'num_leaves': 60, 'max_depth': 6, 'min_child_samples': 70, 'reg_alpha': 0, 'reg_lambda': 9, 'min_split_gain': 1.0, 'subsample': 0.9, 'subsample_freq': 1, 'colsample_bytree': 0.5}. Best is trial 150 with value: 0.897210322125745.\u001b[0m\n",
      "\u001b[32m[I 2022-06-29 19:15:30,995]\u001b[0m Trial 158 finished with value: 0.8944023022518048 and parameters: {'n_estimators': 10000, 'learning_rate': 0.06196816139799948, 'num_leaves': 50, 'max_depth': 6, 'min_child_samples': 80, 'reg_alpha': 0, 'reg_lambda': 9, 'min_split_gain': 0.5, 'subsample': 0.9, 'subsample_freq': 1, 'colsample_bytree': 0.5}. Best is trial 150 with value: 0.897210322125745.\u001b[0m\n",
      "\u001b[32m[I 2022-06-29 19:15:34,128]\u001b[0m Trial 159 finished with value: 0.8967201699003815 and parameters: {'n_estimators': 10000, 'learning_rate': 0.04239175616766124, 'num_leaves': 60, 'max_depth': 6, 'min_child_samples': 50, 'reg_alpha': 0, 'reg_lambda': 9, 'min_split_gain': 0.0, 'subsample': 0.9, 'subsample_freq': 1, 'colsample_bytree': 0.5}. Best is trial 150 with value: 0.897210322125745.\u001b[0m\n",
      "\u001b[32m[I 2022-06-29 19:15:36,799]\u001b[0m Trial 160 finished with value: 0.8947656749988223 and parameters: {'n_estimators': 10000, 'learning_rate': 0.038090361967425844, 'num_leaves': 60, 'max_depth': 6, 'min_child_samples': 70, 'reg_alpha': 0, 'reg_lambda': 9, 'min_split_gain': 0.5, 'subsample': 0.9, 'subsample_freq': 1, 'colsample_bytree': 0.5}. Best is trial 150 with value: 0.897210322125745.\u001b[0m\n",
      "\u001b[32m[I 2022-06-29 19:15:39,648]\u001b[0m Trial 161 finished with value: 0.8968532751188789 and parameters: {'n_estimators': 10000, 'learning_rate': 0.04513142627241724, 'num_leaves': 55, 'max_depth': 6, 'min_child_samples': 50, 'reg_alpha': 0, 'reg_lambda': 9, 'min_split_gain': 0.0, 'subsample': 0.9, 'subsample_freq': 1, 'colsample_bytree': 0.5}. Best is trial 150 with value: 0.897210322125745.\u001b[0m\n",
      "\u001b[32m[I 2022-06-29 19:15:42,507]\u001b[0m Trial 162 finished with value: 0.897018511921241 and parameters: {'n_estimators': 10000, 'learning_rate': 0.04334743786946013, 'num_leaves': 55, 'max_depth': 6, 'min_child_samples': 50, 'reg_alpha': 0, 'reg_lambda': 9, 'min_split_gain': 0.0, 'subsample': 0.9, 'subsample_freq': 1, 'colsample_bytree': 0.5}. Best is trial 150 with value: 0.897210322125745.\u001b[0m\n",
      "\u001b[32m[I 2022-06-29 19:15:45,487]\u001b[0m Trial 163 finished with value: 0.8949701366836288 and parameters: {'n_estimators': 10000, 'learning_rate': 0.026399388917924316, 'num_leaves': 55, 'max_depth': 6, 'min_child_samples': 50, 'reg_alpha': 0, 'reg_lambda': 9, 'min_split_gain': 0.5, 'subsample': 0.9, 'subsample_freq': 1, 'colsample_bytree': 0.5}. Best is trial 150 with value: 0.897210322125745.\u001b[0m\n",
      "\u001b[32m[I 2022-06-29 19:15:47,900]\u001b[0m Trial 164 finished with value: 0.8893240827544443 and parameters: {'n_estimators': 10000, 'learning_rate': 0.05786122417295401, 'num_leaves': 50, 'max_depth': 6, 'min_child_samples': 50, 'reg_alpha': 0, 'reg_lambda': 9, 'min_split_gain': 5.0, 'subsample': 0.9, 'subsample_freq': 1, 'colsample_bytree': 0.5}. Best is trial 150 with value: 0.897210322125745.\u001b[0m\n",
      "\u001b[32m[I 2022-06-29 19:15:50,883]\u001b[0m Trial 165 finished with value: 0.8967295658742463 and parameters: {'n_estimators': 10000, 'learning_rate': 0.04694800066170505, 'num_leaves': 55, 'max_depth': 6, 'min_child_samples': 70, 'reg_alpha': 0, 'reg_lambda': 9, 'min_split_gain': 0.0, 'subsample': 0.9, 'subsample_freq': 1, 'colsample_bytree': 0.5}. Best is trial 150 with value: 0.897210322125745.\u001b[0m\n",
      "\u001b[32m[I 2022-06-29 19:15:53,625]\u001b[0m Trial 166 finished with value: 0.8968448584436985 and parameters: {'n_estimators': 10000, 'learning_rate': 0.04552743174738892, 'num_leaves': 65, 'max_depth': 6, 'min_child_samples': 70, 'reg_alpha': 0, 'reg_lambda': 9, 'min_split_gain': 0.0, 'subsample': 0.9, 'subsample_freq': 1, 'colsample_bytree': 0.5}. Best is trial 150 with value: 0.897210322125745.\u001b[0m\n",
      "\u001b[32m[I 2022-06-29 19:15:55,434]\u001b[0m Trial 167 finished with value: 0.8938830092736939 and parameters: {'n_estimators': 10000, 'learning_rate': 0.04912937034877374, 'num_leaves': 65, 'max_depth': 6, 'min_child_samples': 70, 'reg_alpha': 0, 'reg_lambda': 9, 'min_split_gain': 1.0, 'subsample': 0.9, 'subsample_freq': 1, 'colsample_bytree': 0.5}. Best is trial 150 with value: 0.897210322125745.\u001b[0m\n",
      "\u001b[32m[I 2022-06-29 19:15:57,176]\u001b[0m Trial 168 finished with value: 0.8874340098258067 and parameters: {'n_estimators': 10000, 'learning_rate': 0.04697670754866275, 'num_leaves': 55, 'max_depth': 6, 'min_child_samples': 50, 'reg_alpha': 0, 'reg_lambda': 9, 'min_split_gain': 6.5, 'subsample': 0.9, 'subsample_freq': 1, 'colsample_bytree': 0.5}. Best is trial 150 with value: 0.897210322125745.\u001b[0m\n",
      "\u001b[32m[I 2022-06-29 19:16:02,713]\u001b[0m Trial 169 finished with value: 0.897066127011334 and parameters: {'n_estimators': 10000, 'learning_rate': 0.016725906799310027, 'num_leaves': 65, 'max_depth': 6, 'min_child_samples': 70, 'reg_alpha': 0, 'reg_lambda': 9, 'min_split_gain': 0.0, 'subsample': 0.9, 'subsample_freq': 1, 'colsample_bytree': 0.5}. Best is trial 150 with value: 0.897210322125745.\u001b[0m\n",
      "\u001b[32m[I 2022-06-29 19:16:08,901]\u001b[0m Trial 170 finished with value: 0.8948606405036877 and parameters: {'n_estimators': 10000, 'learning_rate': 0.010916255723880205, 'num_leaves': 65, 'max_depth': 6, 'min_child_samples': 70, 'reg_alpha': 0, 'reg_lambda': 9, 'min_split_gain': 0.5, 'subsample': 0.9, 'subsample_freq': 1, 'colsample_bytree': 0.5}. Best is trial 150 with value: 0.897210322125745.\u001b[0m\n",
      "\u001b[32m[I 2022-06-29 19:16:12,730]\u001b[0m Trial 171 finished with value: 0.896571554708124 and parameters: {'n_estimators': 10000, 'learning_rate': 0.030809202052013908, 'num_leaves': 60, 'max_depth': 6, 'min_child_samples': 80, 'reg_alpha': 0, 'reg_lambda': 9, 'min_split_gain': 0.0, 'subsample': 0.9, 'subsample_freq': 1, 'colsample_bytree': 0.5}. Best is trial 150 with value: 0.897210322125745.\u001b[0m\n",
      "\u001b[32m[I 2022-06-29 19:16:16,288]\u001b[0m Trial 172 finished with value: 0.8963868642697317 and parameters: {'n_estimators': 10000, 'learning_rate': 0.030778375565323368, 'num_leaves': 60, 'max_depth': 6, 'min_child_samples': 80, 'reg_alpha': 0, 'reg_lambda': 9, 'min_split_gain': 0.0, 'subsample': 0.9, 'subsample_freq': 1, 'colsample_bytree': 0.5}. Best is trial 150 with value: 0.897210322125745.\u001b[0m\n",
      "\u001b[32m[I 2022-06-29 19:16:20,015]\u001b[0m Trial 173 finished with value: 0.8967935643666558 and parameters: {'n_estimators': 10000, 'learning_rate': 0.03129462322096568, 'num_leaves': 60, 'max_depth': 6, 'min_child_samples': 50, 'reg_alpha': 0, 'reg_lambda': 9, 'min_split_gain': 0.0, 'subsample': 0.9, 'subsample_freq': 1, 'colsample_bytree': 0.5}. Best is trial 150 with value: 0.897210322125745.\u001b[0m\n",
      "\u001b[32m[I 2022-06-29 19:16:22,957]\u001b[0m Trial 174 finished with value: 0.8948464539065284 and parameters: {'n_estimators': 10000, 'learning_rate': 0.030967664292294195, 'num_leaves': 60, 'max_depth': 6, 'min_child_samples': 50, 'reg_alpha': 0, 'reg_lambda': 9, 'min_split_gain': 0.5, 'subsample': 0.9, 'subsample_freq': 1, 'colsample_bytree': 0.5}. Best is trial 150 with value: 0.897210322125745.\u001b[0m\n",
      "\u001b[32m[I 2022-06-29 19:16:27,931]\u001b[0m Trial 175 finished with value: 0.896805421820998 and parameters: {'n_estimators': 10000, 'learning_rate': 0.019898196629905475, 'num_leaves': 65, 'max_depth': 6, 'min_child_samples': 70, 'reg_alpha': 0, 'reg_lambda': 9, 'min_split_gain': 0.0, 'subsample': 0.9, 'subsample_freq': 1, 'colsample_bytree': 0.5}. Best is trial 150 with value: 0.897210322125745.\u001b[0m\n",
      "\u001b[32m[I 2022-06-29 19:16:31,811]\u001b[0m Trial 176 finished with value: 0.8950616614093326 and parameters: {'n_estimators': 10000, 'learning_rate': 0.01989294292747603, 'num_leaves': 65, 'max_depth': 6, 'min_child_samples': 50, 'reg_alpha': 0, 'reg_lambda': 9, 'min_split_gain': 0.5, 'subsample': 0.9, 'subsample_freq': 1, 'colsample_bytree': 0.5}. Best is trial 150 with value: 0.897210322125745.\u001b[0m\n",
      "\u001b[32m[I 2022-06-29 19:16:35,534]\u001b[0m Trial 177 finished with value: 0.8935836085515536 and parameters: {'n_estimators': 10000, 'learning_rate': 0.019264876799714933, 'num_leaves': 65, 'max_depth': 6, 'min_child_samples': 100, 'reg_alpha': 0, 'reg_lambda': 9, 'min_split_gain': 1.0, 'subsample': 0.9, 'subsample_freq': 1, 'colsample_bytree': 0.5}. Best is trial 150 with value: 0.897210322125745.\u001b[0m\n",
      "\u001b[32m[I 2022-06-29 19:16:38,426]\u001b[0m Trial 178 finished with value: 0.896723054861371 and parameters: {'n_estimators': 10000, 'learning_rate': 0.04475917985802161, 'num_leaves': 60, 'max_depth': 6, 'min_child_samples': 70, 'reg_alpha': 0, 'reg_lambda': 9, 'min_split_gain': 0.0, 'subsample': 0.9, 'subsample_freq': 1, 'colsample_bytree': 0.5}. Best is trial 150 with value: 0.897210322125745.\u001b[0m\n",
      "\u001b[32m[I 2022-06-29 19:16:41,387]\u001b[0m Trial 179 finished with value: 0.8968710348328602 and parameters: {'n_estimators': 10000, 'learning_rate': 0.04466568958154423, 'num_leaves': 65, 'max_depth': 5, 'min_child_samples': 70, 'reg_alpha': 0, 'reg_lambda': 9, 'min_split_gain': 0.0, 'subsample': 0.9, 'subsample_freq': 1, 'colsample_bytree': 0.5}. Best is trial 150 with value: 0.897210322125745.\u001b[0m\n",
      "\u001b[32m[I 2022-06-29 19:16:43,812]\u001b[0m Trial 180 finished with value: 0.8944156418879396 and parameters: {'n_estimators': 10000, 'learning_rate': 0.043120896806355564, 'num_leaves': 65, 'max_depth': 5, 'min_child_samples': 70, 'reg_alpha': 0, 'reg_lambda': 9, 'min_split_gain': 0.5, 'subsample': 0.9, 'subsample_freq': 1, 'colsample_bytree': 0.4}. Best is trial 150 with value: 0.897210322125745.\u001b[0m\n",
      "\u001b[32m[I 2022-06-29 19:16:46,988]\u001b[0m Trial 181 finished with value: 0.8968114034832331 and parameters: {'n_estimators': 10000, 'learning_rate': 0.0387756617334171, 'num_leaves': 55, 'max_depth': 5, 'min_child_samples': 50, 'reg_alpha': 0, 'reg_lambda': 9, 'min_split_gain': 0.0, 'subsample': 0.9, 'subsample_freq': 1, 'colsample_bytree': 0.5}. Best is trial 150 with value: 0.897210322125745.\u001b[0m\n",
      "\u001b[32m[I 2022-06-29 19:16:50,587]\u001b[0m Trial 182 finished with value: 0.896600404318019 and parameters: {'n_estimators': 10000, 'learning_rate': 0.035223458334808985, 'num_leaves': 60, 'max_depth': 5, 'min_child_samples': 50, 'reg_alpha': 0, 'reg_lambda': 9, 'min_split_gain': 0.0, 'subsample': 0.9, 'subsample_freq': 1, 'colsample_bytree': 0.5}. Best is trial 150 with value: 0.897210322125745.\u001b[0m\n",
      "\u001b[32m[I 2022-06-29 19:16:54,212]\u001b[0m Trial 183 finished with value: 0.8967295658742465 and parameters: {'n_estimators': 10000, 'learning_rate': 0.03605120739539945, 'num_leaves': 60, 'max_depth': 5, 'min_child_samples': 50, 'reg_alpha': 0, 'reg_lambda': 9, 'min_split_gain': 0.0, 'subsample': 0.9, 'subsample_freq': 1, 'colsample_bytree': 0.5}. Best is trial 150 with value: 0.897210322125745.\u001b[0m\n",
      "\u001b[32m[I 2022-06-29 19:16:56,420]\u001b[0m Trial 184 finished with value: 0.8948239829718486 and parameters: {'n_estimators': 10000, 'learning_rate': 0.04316329960946794, 'num_leaves': 70, 'max_depth': 4, 'min_child_samples': 50, 'reg_alpha': 0, 'reg_lambda': 9, 'min_split_gain': 0.5, 'subsample': 0.9, 'subsample_freq': 1, 'colsample_bytree': 0.5}. Best is trial 150 with value: 0.897210322125745.\u001b[0m\n",
      "\u001b[32m[I 2022-06-29 19:16:59,781]\u001b[0m Trial 185 finished with value: 0.8967480402115919 and parameters: {'n_estimators': 10000, 'learning_rate': 0.03624711119663028, 'num_leaves': 50, 'max_depth': 5, 'min_child_samples': 50, 'reg_alpha': 0, 'reg_lambda': 9, 'min_split_gain': 0.0, 'subsample': 0.9, 'subsample_freq': 1, 'colsample_bytree': 0.5}. Best is trial 150 with value: 0.897210322125745.\u001b[0m\n",
      "\u001b[32m[I 2022-06-29 19:17:05,204]\u001b[0m Trial 186 finished with value: 0.8948618315426283 and parameters: {'n_estimators': 10000, 'learning_rate': 0.011499349788193038, 'num_leaves': 50, 'max_depth': 5, 'min_child_samples': 70, 'reg_alpha': 0, 'reg_lambda': 9, 'min_split_gain': 0.5, 'subsample': 0.9, 'subsample_freq': 1, 'colsample_bytree': 0.5}. Best is trial 150 with value: 0.897210322125745.\u001b[0m\n",
      "\u001b[32m[I 2022-06-29 19:17:08,314]\u001b[0m Trial 187 finished with value: 0.8967197464198693 and parameters: {'n_estimators': 10000, 'learning_rate': 0.04196833349937296, 'num_leaves': 50, 'max_depth': 5, 'min_child_samples': 50, 'reg_alpha': 0, 'reg_lambda': 9, 'min_split_gain': 0.0, 'subsample': 0.9, 'subsample_freq': 1, 'colsample_bytree': 0.5}. Best is trial 150 with value: 0.897210322125745.\u001b[0m\n",
      "\u001b[32m[I 2022-06-29 19:17:11,429]\u001b[0m Trial 188 finished with value: 0.8834558603615359 and parameters: {'n_estimators': 10000, 'learning_rate': 0.0226975892020345, 'num_leaves': 55, 'max_depth': 4, 'min_child_samples': 70, 'reg_alpha': 0, 'reg_lambda': 9, 'min_split_gain': 10.0, 'subsample': 0.9, 'subsample_freq': 1, 'colsample_bytree': 0.5}. Best is trial 150 with value: 0.897210322125745.\u001b[0m\n",
      "\u001b[32m[I 2022-06-29 19:17:13,714]\u001b[0m Trial 189 finished with value: 0.8935384284744061 and parameters: {'n_estimators': 10000, 'learning_rate': 0.03252894262562746, 'num_leaves': 55, 'max_depth': 5, 'min_child_samples': 100, 'reg_alpha': 0, 'reg_lambda': 9, 'min_split_gain': 1.0, 'subsample': 0.9, 'subsample_freq': 1, 'colsample_bytree': 0.5}. Best is trial 150 with value: 0.897210322125745.\u001b[0m\n",
      "\u001b[32m[I 2022-06-29 19:17:15,846]\u001b[0m Trial 190 finished with value: 0.8945249263276247 and parameters: {'n_estimators': 10000, 'learning_rate': 0.0474404563938815, 'num_leaves': 65, 'max_depth': 4, 'min_child_samples': 50, 'reg_alpha': 0, 'reg_lambda': 9, 'min_split_gain': 0.5, 'subsample': 0.9, 'subsample_freq': 1, 'colsample_bytree': 0.5}. Best is trial 150 with value: 0.897210322125745.\u001b[0m\n",
      "\u001b[32m[I 2022-06-29 19:17:19,143]\u001b[0m Trial 191 finished with value: 0.8969242081046761 and parameters: {'n_estimators': 10000, 'learning_rate': 0.04344346221080645, 'num_leaves': 50, 'max_depth': 5, 'min_child_samples': 50, 'reg_alpha': 0, 'reg_lambda': 9, 'min_split_gain': 0.0, 'subsample': 0.9, 'subsample_freq': 1, 'colsample_bytree': 0.5}. Best is trial 150 with value: 0.897210322125745.\u001b[0m\n",
      "\u001b[32m[I 2022-06-29 19:17:23,514]\u001b[0m Trial 192 finished with value: 0.8967492047830006 and parameters: {'n_estimators': 10000, 'learning_rate': 0.026012545476662072, 'num_leaves': 50, 'max_depth': 5, 'min_child_samples': 70, 'reg_alpha': 0, 'reg_lambda': 9, 'min_split_gain': 0.0, 'subsample': 0.9, 'subsample_freq': 1, 'colsample_bytree': 0.5}. Best is trial 150 with value: 0.897210322125745.\u001b[0m\n",
      "\u001b[32m[I 2022-06-29 19:17:28,615]\u001b[0m Trial 193 finished with value: 0.8970317456872479 and parameters: {'n_estimators': 10000, 'learning_rate': 0.0222289001798866, 'num_leaves': 50, 'max_depth': 5, 'min_child_samples': 70, 'reg_alpha': 0, 'reg_lambda': 9, 'min_split_gain': 0.0, 'subsample': 0.9, 'subsample_freq': 1, 'colsample_bytree': 0.5}. Best is trial 150 with value: 0.897210322125745.\u001b[0m\n",
      "\u001b[32m[I 2022-06-29 19:17:31,598]\u001b[0m Trial 194 finished with value: 0.894439462666752 and parameters: {'n_estimators': 10000, 'learning_rate': 0.026253742888768465, 'num_leaves': 50, 'max_depth': 5, 'min_child_samples': 90, 'reg_alpha': 0, 'reg_lambda': 8, 'min_split_gain': 0.5, 'subsample': 0.9, 'subsample_freq': 1, 'colsample_bytree': 0.5}. Best is trial 150 with value: 0.897210322125745.\u001b[0m\n",
      "\u001b[32m[I 2022-06-29 19:17:39,406]\u001b[0m Trial 195 finished with value: 0.8968455730670628 and parameters: {'n_estimators': 10000, 'learning_rate': 0.010699093948052591, 'num_leaves': 50, 'max_depth': 5, 'min_child_samples': 70, 'reg_alpha': 0, 'reg_lambda': 9, 'min_split_gain': 0.0, 'subsample': 0.9, 'subsample_freq': 1, 'colsample_bytree': 0.5}. Best is trial 150 with value: 0.897210322125745.\u001b[0m\n",
      "\u001b[32m[I 2022-06-29 19:17:44,996]\u001b[0m Trial 196 finished with value: 0.8969324924421962 and parameters: {'n_estimators': 10000, 'learning_rate': 0.015411755611886693, 'num_leaves': 50, 'max_depth': 5, 'min_child_samples': 90, 'reg_alpha': 0, 'reg_lambda': 9, 'min_split_gain': 0.0, 'subsample': 0.9, 'subsample_freq': 1, 'colsample_bytree': 0.5}. Best is trial 150 with value: 0.897210322125745.\u001b[0m\n",
      "\u001b[32m[I 2022-06-29 19:17:50,600]\u001b[0m Trial 197 finished with value: 0.8943463498891274 and parameters: {'n_estimators': 10000, 'learning_rate': 0.013725635227535206, 'num_leaves': 50, 'max_depth': 5, 'min_child_samples': 100, 'reg_alpha': 0, 'reg_lambda': 9, 'min_split_gain': 0.5, 'subsample': 0.9, 'subsample_freq': 1, 'colsample_bytree': 0.5}. Best is trial 150 with value: 0.897210322125745.\u001b[0m\n",
      "\u001b[32m[I 2022-06-29 19:17:55,782]\u001b[0m Trial 198 finished with value: 0.8970502729596577 and parameters: {'n_estimators': 10000, 'learning_rate': 0.022032269800488394, 'num_leaves': 50, 'max_depth': 5, 'min_child_samples': 70, 'reg_alpha': 0, 'reg_lambda': 9, 'min_split_gain': 0.0, 'subsample': 0.9, 'subsample_freq': 1, 'colsample_bytree': 0.5}. Best is trial 150 with value: 0.897210322125745.\u001b[0m\n",
      "\u001b[32m[I 2022-06-29 19:18:00,045]\u001b[0m Trial 199 finished with value: 0.8941892121515616 and parameters: {'n_estimators': 10000, 'learning_rate': 0.01862996976199042, 'num_leaves': 50, 'max_depth': 5, 'min_child_samples': 110, 'reg_alpha': 0, 'reg_lambda': 9, 'min_split_gain': 0.5, 'subsample': 0.9, 'subsample_freq': 1, 'colsample_bytree': 0.5}. Best is trial 150 with value: 0.897210322125745.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*************************** Final Logistic Regression Model***************************\n",
      "   Fold 1 ---- Train AUC: 0.943462   Valid AUC: 0.896225\n",
      "   Fold 2 ---- Train AUC: 0.949646   Valid AUC: 0.902057\n",
      "   Fold 3 ---- Train AUC: 0.934627   Valid AUC: 0.899355\n",
      "   Fold 4 ---- Train AUC: 0.942426   Valid AUC: 0.902678\n",
      "   Fold 5 ---- Train AUC: 0.937660   Valid AUC: 0.886748\n",
      "   Overall AUC:   0.897209\n"
     ]
    }
   ],
   "source": [
    "sub = OptimizationModelLGBM(train, test, 'PassengerId', 'Transported')\n",
    "sub.to_csv(os.getcwd()+'\\\\Submission14_SpS_Titanic.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fa797111-3d70-47a5-b655-b49bb6f9b3b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sub = OptimizationModel(train, test, 'PassengerId', 'Transported')\n",
    "# sub.to_csv(os.getcwd()+'\\\\Submission11_SpS_Titanic.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a05db177-59f5-4c37-a1eb-027fcb294279",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sub = BaselineModels(train, test, 'PassengerId', 'Transported', n_folds = 5, seed = 42069)\n",
    "# sub.to_csv(os.getcwd()+'\\\\Submission9_SpS_Titanic.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "25b6b140-ff27-4b51-a9f6-d3d67d2d2624",
   "metadata": {},
   "outputs": [],
   "source": [
    "# testdict = {'1':1,'2':2}\n",
    "# list(testdict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52799c51-a0d3-4aae-be36-72a795b745c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
